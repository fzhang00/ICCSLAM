@inproceedings{klippenstein_performance_2009,
	title = {Performance Evaluation of Visual {SLAM} Using Several Feature Extractors},
	doi = {10.1109/IROS.2009.5354001},
	abstract = {Visual simultaneous localization and mapping ({SLAM}) implementations must use feature extraction to reduce the dimensionality of image input, yet no comparison of feature extractors exists in the context of visual {SLAM}. This paper presents both a method for comparison of visual {SLAM} performance using several different feature extractors and the first experimental study using this method. Possible evaluation metrics are discussed and consistency testing and accumulated uncertainty are chosen to measure performance. Three feature extractors commonly used for visual {SLAM} are examined: the Harris corner detector, the Kanade-Lucas-Tomasi tracker, and the scale-invariant feature transform. All three are found to perform similarly in an indoor test environment, close to or within the limits of measurement. A modest scale change is handled without difficulty. We conclude that feature extractor choice is not significant in terms of visual {SLAM} performance and other criteria may be used to make the selection.},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Klippenstein, J. and Zhang, Hong},
	year = {2009},
	keywords = {Cameras, consistency testing, Detectors, feature extraction, Feature extraction, feature extractor, Harris corner detector, image dimensionality, Intelligent robots, Kanade-Lucas-Tomasi tracker, optical tracking, Particle measurements, Robot sensing systems, robot vision, Robot vision systems, scale-invariant feature transform, Simultaneous localization and mapping, {SLAM} (robots), Testing, Uncertainty, visual simultaneous localization and mapping, Visual {SLAM}},
	pages = {1574--1581},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\7IR3Q3MP\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GJNDBM35\\Klippenstein and Zhang - 2009 - Performance evaluation of visual SLAM using severa.pdf:application/pdf}
}

@book{grewal_kalman_1993,
	address = {Englewood Cliffs, N.J},
	title = {Kalman Filtering: Theory and Practice},
	isbn = {013211335X},
	shorttitle = {Kalman filtering},
	publisher = {Prentice-Hall},
	author = {Grewal, Mohinder S.},
	collaborator = {Andrews, Angus P.},
	year = {1993},
	keywords = {Kalman filtering}
}

@article{smith_approaches_2006,
	title = {Approaches to Multisensor Data Fusion in Target Tracking: A Survey},
	volume = {18},
	issn = {1041-4347},
	shorttitle = {Approaches to Multisensor Data Fusion in Target Tracking},
	doi = {10.1109/TKDE.2006.183},
	abstract = {The tracking of objects using distributed multiple sensors is an important field of work in the application areas of autonomous robotics, military applications, and mobile systems. In this survey, we review a number of computationally intelligent methods that are used for developing robust tracking schemes through sensor data fusion. The survey discusses the application of the various algorithms at different layers of the {JDL} model and highlights the weaknesses and strengths of the approaches in the context of different applications},
	number = {12},
	journal = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Smith, D. and Singh, S.},
	year = {2006},
	keywords = {Competitive intelligence, Computational intelligence, data fusion., distributed multiple sensors, distributed sensors, information fusion, Intelligent robots, Intelligent sensors, {JDL} model, Military computing, mobile robots, multisensor data fusion, Robot sensing systems, robust tracking, Robustness, sensor fusion, Sensor systems and applications, Target tracking, Tracking},
	pages = {1696--1710},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\MBJFX5WD\\login.html:text/html}
}

@article{chowdhury_stochastic_2003,
	title = {Stochastic Approximation and Rate-Distortion Analysis for Robust Structure and Motion Estimation},
	volume = {55},
	issn = {0920-5691, 1573-1405},
	doi = {10.1023/A:1024488407740},
	abstract = {Recent research on structure and motion recovery has focused on issues related to sensitivity and robustness of existing techniques. One possible reason is that in practical applications, the underlying assumptions made by existing algorithms are often violated. In this paper, we propose a framework for 3D reconstruction from short monocular video sequences taking into account the statistical errors in reconstruction algorithms. Detailed error analysis is especially important for this problem because the motion between pairs of frames is small and slight perturbations in its estimates can lead to large errors in 3D reconstruction. We focus on the following issues: physical sources of errors, their experimental and theoretical analysis, robust estimation techniques and measures for characterizing the quality of the final reconstruction. We derive a precise relationship between the error in the reconstruction and the error in the image correspondences. The error analysis is used to design a robust, recursive multi-frame fusion algorithm using “stochastic approximation” as the framework since it is capable of dealing with incomplete information about errors in observations. Rate-distortion analysis is proposed for evaluating the quality of the final reconstruction as a function of the number of frames and the error in the image correspondences. Finally, to demonstrate the effectiveness of the algorithm, examples of depth reconstruction are shown for different video sequences.},
	language = {en},
	number = {1},
	urldate = {2013-11-26},
	journal = {International Journal of Computer Vision},
	author = {Chowdhury, Amit K. Roy and Chellappa, R.},
	month = oct,
	year = {2003},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, Error analysis, Image processing, rate distortion theory, Robbins-Monro stochastic approximation, structure and motion estimation},
	pages = {27--53},
	file = {Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\JBQZFE7B\\10.html:text/html}
}

@inproceedings{rosten_machine_2006,
	title = {Machine Learning for High-speed Corner Detection},
	abstract = {Where feature points are used in real-time frame-rate applications,  a high-speed feature detector is necessary. Feature detectors such  as {SIFT} ({DoG}), Harris and {SUSAN} are good methods which yield high  quality features, however they are too computationally intensive for use  in real-time applications of any complexity. Here we show that machine  learning can be used to derive a feature detector which can fully process  live {PAL} video using less than 7\% of the available processing time. By  comparison neither the Harris detector (120\%) nor the detection stage  of {SIFT} (300\%) can operate at full frame rate.},
	booktitle = {Proceedings of the European Conference on Computer Vision},
	author = {Rosten, Edward and Drummond, Tom},
	year = {2006},
	pages = {430--443},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\NW9ABTUK\\Rosten and Drummond - 2006 - Machine learning for high-speed corner detection.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\9BW2C9JT\\summary.html:text/html}
}

@book{lewis_optimal_1986,
	address = {New York},
	title = {Optimal Estimation: with an Introduction to Stochastic Control Theory},
	isbn = {0471837415},
	shorttitle = {Optimal estimation},
	publisher = {Wiley},
	author = {Lewis, Frank L.},
	year = {1986},
	keywords = {Mathematical optimization, Stochastic control theory}
}

@article{reninger_singular_2011,
	title = {Singular Value Decomposition as a Denoising Tool for Airborne Time Domain Electromagnetic Data},
	volume = {75},
	issn = {0926-9851},
	url = {http://www.sciencedirect.com/science/article/pii/S0926985111001418},
	doi = {10.1016/j.jappgeo.2011.06.034},
	abstract = {Airborne time domain electromagnetic ({TDEM}) surveys are increasingly carried out in anthropized areas as part of environmental studies. In such areas, noise arises mainly from either natural sources, such as spherics, or cultural sources, such as couplings with man-made installations. This results in various distortions on the measured decays, which make the {EM} noise spectrum complex and may lead to erroneous inversion and subsequent misinterpretations. Thresholding and stacking standard techniques, commonly used to filter {TDEM} data, are less efficient in such environment, requiring a time-consuming and subjective manual editing. The aim of this study was therefore to propose an alternative fast and efficient user-assisted filtering approach. This was achieved using the singular value decomposition ({SVD}). The {SVD} method uses the principal component analysis to extract into components the dominant shapes from a series of raw input curves. {EM} decays can then be reconstructed with particular components only. To do so, we had to adapt and implement the {SVD}, firstly, to separate clearly and so identify easily the components containing the geological signal, and then to denoise properly {TDEM} data. The reconstructed decays were used to detect noisy gates on their corresponding measured decays. This denoising step allowed rejecting efficiently mainly spikes and oscillations. Then, we focused on couplings with man-made installations, which may result in artifacts on the inverted models. An analysis of the map of weights of the selected “noisy components” highlighted high correlations with man-made installations localized by the flight video. We had therefore a tool to cull most likely decays biased by capacitive coupling noises. Finally, rejection of decays affected by galvanic coupling noises was also possible locating them through the analysis of specific {SVD} components. This {SVD} procedure was applied on airborne {TDEM} data surveyed by {SkyTEM} Aps. over an anthropized area, on behalf of the French geological survey ({BRGM}), near Courtenay in Région Centre, France. The established denoising procedure provides accurate denoising tools and makes, at least, the manual cleaning less time consuming and less subjective.},
	number = {2},
	urldate = {2013-05-24},
	journal = {Journal of Applied Geophysics},
	author = {Reninger, P.-A. and Martelet, G. and Deparis, J. and Perrin, J. and Chen, Y.},
	month = oct,
	year = {2011},
	keywords = {Airborne, Denoising, Filter, Singular value decomposition ({SVD}), Time domain electromagnetism ({TDEM}), Transient electromagnetism ({TEM})},
	pages = {264--276},
	file = {Reninger-JAppliedGeophysics-2011.pdf:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\8X3WVHH6\\Reninger-JAppliedGeophysics-2011.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GN2XU3CF\\S0926985111001418.html:text/html}
}

@inproceedings{matthies_stereo_2014,
	title = {Stereo vision-based obstacle avoidance for micro air vehicles using disparity space},
	doi = {10.1109/ICRA.2014.6907325},
	abstract = {We address obstacle avoidance for outdoor flight of micro air vehicles. The highly textured nature of outdoor scenes enables camera-based perception, which will scale to very small size, weight, and power with very wide, two-axis field of regard. In this paper, we use forward-looking stereo cameras for obstacle detection and a downward-looking camera as an input to state estimation. For obstacle representation, we use image space with the stereo disparity map itself. We show that a C-space-like obstacle expansion can be done with this representation and that collision checking can be done by projecting candidate 3-D trajectories into image space and performing a z-buffer-like operation with the disparity map. This approach is very efficient in memory and computing time. We do motion planning and trajectory generation with an adaptation of a closed-loop {RRT} planner to quadrotor dynamics and full 3D search. We validate the performance of the system with Monte Carlo simulations in virtual worlds and flight tests of a real quadrotor through a grove of trees. The approach is designed to support scalability to high speed flight and has numerous possible generalizations to use other polar or hybrid polar/Cartesian representations and to fuse data from additional sensors, such as peripheral optical flow or radar.},
	booktitle = {2014 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	author = {Matthies, L. and Brockers, R. and Kuwata, Y. and Weiss, S.},
	month = may,
	year = {2014},
	keywords = {3D search, 3-D trajectories, autonomous aerial vehicles, camera-based perception, Cameras, closed-loop {RRT} planner, collision avoidance, collision checking, C-space-like obstacle expansion, disparity space, downward-looking camera, flight tests, forward-looking stereo cameras, helicopters, high speed flight, micro air vehicles, Monte Carlo simulations, motion planning, obstacle detection, obstacle representation, Optical imaging, Optical sensors, outdoor flight, Planning, quadrotor dynamics, robot vision, state estimation, stereo disparity map, stereo image processing, stereo vision-based obstacle avoidance, Three-dimensional displays, Trajectory, trajectory generation, tree grove, Vehicles, virtual worlds, z-buffer-like operation},
	pages = {3242--3249},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GZZ342RE\\Matthies et al. - 2014 - Stereo vision-based obstacle avoidance for micro a.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\74C7ZJM4\\Matthies et al. - 2014 - Stereo vision-based obstacle avoidance for micro a.pdf:application/pdf}
}

@inproceedings{kerr_comparing_2008,
	title = {Comparing Cornerness Measures for Interest Point Detection},
	doi = {10.1109/IMVIP.2008.28},
	abstract = {Interest point detection is used in many computer vision applications that require fast and efficient feature matching. For tasks such as robot localisation and navigation, the use of interest points for matching is preferred over edges or other, larger, features. Recently, finite-element based methods have been used to develop gradient operators for edge and interest point detection. We extend this work to alternative corner detection measures and provide a comparative evaluation of some different techniques.},
	booktitle = {Proceedings of the Machine Vision and Image Processing Conference},
	author = {Kerr, D. and Coleman, S. and Scotney, B.},
	year = {2008},
	keywords = {Application software, computer vision, computer vision application, corner detection, Detectors, edge detection, feature matching, finite element analysis, finite-element based method, gradient methods, gradient operator, Image edge detection, image matching, Image processing, Intelligent robots, Intelligent systems, interest point detection, Machine intelligence, Machine vision, Navigation, robot localisation, robot navigation},
	pages = {105--110},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\IN8JAEJU\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\PRVRUWAS\\Kerr et al. - 2008 - Comparing Cornerness Measures for Interest Point D.pdf:application/pdf}
}

@incollection{durrant-whyte_localization_1996,
	title = {Localization of Autonomous Guided Vehicles},
	copyright = {©1996 Springer-Verlag London},
	isbn = {978-1-4471-1257-0, 978-1-4471-1021-7},
	abstract = {This paper reviews and describes the state-of-the-art in localization of autonomous guided vehicles ({AGVs}). The localization problem, the ability to accurately sense and estimate the location of a platform, lies at the heart of almost all {AGV} applications. Solving the localization problem is an essential precursor to more complex {AGV} tasks such as planing and task execution.},
	language = {en},
	urldate = {2013-08-24},
	booktitle = {Robotics Research},
	publisher = {Springer London},
	author = {Durrant-Whyte, Hugh and Rye, David and Nebot, Eduardo},
	month = jan,
	year = {1996},
	keywords = {Energy Technology, Image Processing and Computer Vision},
	pages = {613--625},
	file = {Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\X9MMUXTH\\978-1-4471-1021-7_69.html:text/html}
}

@inproceedings{hashimoto_detection_1996,
	title = {Detection of Obstacle from Monocular Vision Based on Histogram Matching Method},
	volume = {2},
	doi = {10.1109/IECON.1996.566023},
	abstract = {This paper proposes a detection method of an unknown obstacle trespassing upon the field of view from a monocular vision installed in an autonomous land vehicle which moves in the unknown static environment. Taking account of the motion restriction of the vehicle, we investigate the vanishing point of motion and the direction of each optical flow as the motion vector observed on a 2D-image. Then, in the case of no obstacles, it is shown that the vector field forms a uniform radial configuration centered at the vanishing point of motion. In this paper, the obstacle detection is performed by extracting a certain disturbed region in the vector field caused by the trespassing obstacle. The normalized histogram matching method suitable for obtaining the vector field is introduced. The experimental result for the real images in the case of an obstacle trespassing upon the field of view is shown},
	booktitle = {Proceedings of the 22nd {IEEE} International Conference on Industrial Electronics, Control, and Instrumentation},
	author = {Hashimoto, H. and Yamaura, T. and Higashiguchi, M.},
	year = {1996},
	keywords = {2D-image, Automotive engineering, autonomous land vehicle, Cameras, histogram matching method, Histograms, Image motion analysis, Land vehicles, mobile robots, monocular vision, motion vanishing point, object detection, obstacle detection, optical flow direction, Optical noise, Remotely operated vehicles, robot vision, Testing, uniform radial configuration, unknown static environment, Vehicle detection, Working environment noise},
	pages = {1047--1051},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\4QFTC654\\articleDetails.html:text/html}
}

@article{estrada_hierarchical_2005,
	title = {Hierarchical {SLAM}: Real-Time Accurate Mapping of Large Environments},
	volume = {21},
	issn = {1552-3098},
	shorttitle = {Hierarchical {SLAM}},
	doi = {10.1109/TRO.2005.844673},
	abstract = {In this paper, we present a hierarchical mapping method that allows us to obtain accurate metric maps of large environments in real time. The lower (or local) map level is composed of a set of local maps that are guaranteed to be statistically independent. The upper (or global) level is an adjacency graph whose arcs are labeled with the relative location between local maps. An estimation of these relative locations is maintained at this level in a relative stochastic map. We propose a close to optimal loop closing method that, while maintaining independence at the local level, imposes consistency at the global level at a computational cost that is linear with the size of the loop. Experimental results demonstrate the efficiency and precision of the proposed method by mapping the Ada Byron building at our campus. We also analyze, using simulations, the precision and convergence of our method for larger loops.},
	number = {4},
	journal = {{IEEE} Transactions on Robotics},
	author = {Estrada, C. and Neira, J. and Tardos, J.D.},
	year = {2005},
	keywords = {Ada Byron building, Analytical models, closed loop systems, computational complexity, Computational efficiency, Computational modeling, Convergence, hierarchical mapping method, Information filtering, Information filters, Large maps, Local maps, loop closing, metric maps, mobile robots, optimal loop closing method, path planning, Robots, Simultaneous localization and mapping, stochastic mapping, Stochastic processes},
	pages = {588--596},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\KHAZV68K\\login.html:text/html}
}

@inproceedings{harb_neural_2008,
	title = {Neural Networks for Environmental Recognition and Navigation of a Mobile Robot},
	doi = {10.1109/IMTC.2008.4547207},
	abstract = {Mobile robots could play a significant role in places where it is impossible for the human to work. In such environments, neural networks, instead of traditional methods, are suitable solutions to locally navigate and recognize the environment's subspaces. In order to learn and perform two important functions "environmental recognition " and "local navigation ", multi-layered neural networks are trained to process distance measurements received from a laser range-finder. These neural networks are a major component of the control system of a mobile robot dedicated for industrial applications. This paper will focus on a computer based design and test of a neural system, that includes three neural controllers for local navigation, and two neural networks for environmental recognition, fed off-line by a simulated model of a laser range-finder.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Harb, M. and Abielmona, R. and Naji, K. and Petriu, E.},
	year = {2008},
	keywords = {Autonomous Robotic Navigation, Control systems, distance measurement, distance measurements, Electrical equipment industry, environmental recognition, Humans, Industrial control, laser range-finder, laser ranging, mobile robot, mobile robots, Multi-layer neural network, Navigation, neural controllers, neural nets, neural networks, neurocontrollers, object recognition, path planning, Performance evaluation, robot navigation},
	pages = {1123--1128},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\26ZWAT6T\\login.html:text/html}
}

@article{sorenson_least-squares_1970,
	title = {Least-squares Estimation: from {Gauss} to {Kalman}},
	volume = {7},
	issn = {0018-9235},
	shorttitle = {Least-squares estimation},
	doi = {10.1109/MSPEC.1970.5213471},
	abstract = {This discussion is directed to least-squares estimation theory, from its inception by Gauss1 to its modern form, as developed by Kalman.2 To aid in furnishing the desired perspective, the contributions and insights provided by Gauss are described and related to developments that have appeared more recently (that is, in the 20th century). In the author's opinion, it is enlightening to consider just how far (or how little) we have advanced since the initial developments and to recognize the truth in the saying that we “stand on the shoulders of giants.”},
	number = {7},
	journal = {{IEEE} Spectrum},
	author = {Sorenson, H.W.},
	year = {1970},
	keywords = {Books, Estimation theory, Extraterrestrial measurements, Gaussian processes, Kalman filters, Least squares approximation, Least squares methods, Mathematics, Orbits, Planets},
	pages = {63--68},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\34NDCUA7\\login.html:text/html}
}

@inproceedings{kanwal_statistical_2011,
	title = {A Statistical Approach for Comparing the Performances of Corner Detectors},
	doi = {10.1109/PACRIM.2011.6032913},
	abstract = {Corner detectors are widely used in computer vision. This paper assesses several state-of-the-art corner detectors in terms of overall performance and the internal angles of corners using simple geometric shapes. This assessment is carried out using a statistically-valid null hypothesis approach, not previously used in computer vision. It is found that there are statistically significant differences in performance. Moreover, the null hypothesis approach is easy to use in comparing vision techniques.},
	booktitle = {Proceedings of the {IEEE} Pacific Rim Conference on Communications, Computers and Signal Processing},
	author = {Kanwal, N. and Ehsan, S. and Bostanci, E. and Clark, A.F.},
	year = {2011},
	keywords = {Accuracy, computer vision, corner angle, corner detectors, Detectors, edge detection, geometric shapes, Humans, Prediction algorithms, Sensitivity, Shape, statistical analysis, statistically-valid null hypothesis approach},
	pages = {321--326},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\K8RR9NNG\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\H8U9SWXR\\Kanwal et al. - 2011 - A statistical approach for comparing the performan.pdf:application/pdf}
}

@inproceedings{lu_distance_2010,
	title = {Distance and Angle Measurement of Distant Objects on an Oblique Plane Based on Pixel Variation of {CCD} Image},
	doi = {10.1109/IMTC.2010.5488218},
	abstract = {This paper presents an image-based system for measuring target objects on an oblique plane based on pixel variation of {CCD} images for digital cameras by referencing to two arbitrarily designated points in image frames. Based on an established relationship between the displacement of the camera movement along the photographing direction and the difference in pixel counts between reference points in the images, photographing distance between the camera and an object on the oblique target plane can be calculated via the proposed method.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Lu, Ming Chih and Hsu, Chen Chien and Lu, Yin Yu},
	year = {2010},
	keywords = {angle measurement, angular measurement, Area measurement, {CCD} image, {CCD} image sensors, {CCD} images, Charge coupled devices, Charge-coupled image sensors, digital camera, Digital cameras, distance measurement, distant object, Goniometers, Image analysis, image based system, image-based measuring systems, incline angle, oblique plane, Pattern recognition, photographing direction, photographing distance, Pixel, pixel variation, pixels, target object measurement, Ultrasonic variables measurement},
	pages = {318--322},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\H6DMTCJU\\login.html:text/html}
}

@misc{_gps_????,
	title = {{GPS} Accuracy},
	url = {http://www.gps.gov/systems/gps/performance/accuracy/}
}

@inproceedings{jianli_unscented_2011,
	title = {Unscented {FastSLAM} for {UAV}},
	volume = {4},
	doi = {10.1109/ICCSNT.2011.6182484},
	abstract = {Simultaneous localization and mapping ({SLAM}) is a necessary prerequisite to make mobile vehicle truly autonomous, which is a hot research topic today. {FastSLAM} as a successful {SLAM} method abstracts many researchers' attentions. {FastSLAM} factors the {SLAM} problem into a localization problem and a mapping problem in which the landmark position is estimated by {EKF}. A modified {FastSLAM} is presented for uninhabited aerial vehicle ({UAV}), using {UKF} to replace the {EKF} to estimate the landmark position. So we can improve the estimation precision, at the same time no need to linearize the sensor observation model and to compute its Jacobian matrix.},
	booktitle = {Proceedings of the  International Conference on Computer Science and Network Technology},
	author = {Jianli, Shi and Shuang, Pan and Yugiang, Wu and Xibin, Wang},
	year = {2011},
	keywords = {autonomous aerial vehicles, autonomous mobile vehicle, Boolean functions, Data structures, {EKF}, extend Kalman filter ({EKF}), {FastSLAM}, Jacobian matrices, Jacobian matrix, Kalman filters, landmark position estimation, nonlinear filters, sensor observation model, Simultaneous localization and mapping, simultaneous localization and mapping ({SLAM}), {SLAM} (robots), {SLAM} method, {UAV}, {UKF}, uninhabited aerial vehicle, unscented {FastSLAM}, unscented Kalman filter ({UKF})},
	pages = {2529--2532},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\7QBNBNRA\\abstractAuthors.html:text/html}
}

@inproceedings{van_der_mark_stereo_2007,
	title = {Stereo Based Obstacle Detection with Uncertainty in Rough Terrain},
	doi = {10.1109/IVS.2007.4290248},
	abstract = {Autonomous robot vehicles that operate in off-road terrain should avoid obstacle hazards. In this paper we present a stereo vision based method that is able to cluster reconstructed terrain points into obstacles by evaluating their relative angles and distances. In our approach, constraints are enforced on these geometric properties by a set of pixel threshold values. Because these values are all computed during an initialisation step, only simple pixel threshold operations remain to be performed during the real-time obstacle detection. An advantage of this novel approach is that the distance uncertainties can be incorporated into the thresholds. Detected obstacle points are clustered into objects on the basis of their pixel connectivity. Objects with insufficient pixels, elevation and slope are rejected. Remaining non-obstacle pixels are regarded as ground surface points. They are used to update the orientation of the stereo camera relative to the ground surface. This prevents orientation errors during stereo reconstruction and the subsequent obstacle detection steps. Our results show the drawbacks of ignoring the uncertainties in the stereo distance estimates for obstacle detection. It leads to over-segmentation and increases the number of falsely detected obstacles. Because our method incorporates these uncertainties, it can detect more of the obstacle surface pixels at larger distances. This leads to significantly less false obstacle detections.},
	booktitle = {Proceedings of the {IEEE} Intelligent Vehicles Symposium},
	author = {Van der Mark, W. and Van Den Heuvel, J.C. and Groen, F. C A},
	year = {2007},
	keywords = {autonomous robot vehicles, Cameras, collision avoidance, geometric properties, Hazards, image reconstruction, image segmentation, mobile robots, nonobstacle pixels, obstacle hazard avoidance, off-road terrain, orientation errors, over-segmentation, pattern clustering, pixel threshold values, reconstructed terrain point clustering, relative angles, relative distances, Remotely operated vehicles, road vehicles, Robot sensing systems, robot vision, Robot vision systems, rough terrain, stereo based obstacle detection, stereo image processing, stereo reconstruction, stereo vision, stereo vision based method, Surface reconstruction, terrain mapping, Uncertainty, uncertainty handling, Vehicle detection},
	pages = {1005--1012},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\M9NW3K3R\\articleDetails.html:text/html}
}

@misc{_proj.4_????,
	title = {{PROJ}.4},
	url = {https://trac.osgeo.org/proj/},
	urldate = {2013-06-02},
	file = {PROJ.4:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\XHNWZAPV\\proj.html:text/html}
}

@inproceedings{xu_method_2009,
	title = {A Method of Stereo Obstacle Detection Based on Image Symmetrical Move},
	doi = {10.1109/IVS.2009.5164249},
	abstract = {A stereo obstacle detection method based on images symmetrical move and cell partition is presented in this paper. This algorithm gets each cell's optimum offset by calculating the minimum non-similarity of cell, and merges Cell of Interests ({COIs}) to calculate obstacles in the most probably obstacle regions, and gives information of these obstacles. The paper introduces the perspective projection model at first, and then gives two conclusions which are the basic of the algorithm, the part of cell partition and cell optimum offset calculation are presented. Finally, algorithm performance tested by experiment on the test vehicle {JJUV}-I is shown in the paper.},
	booktitle = {Proceedings of the {IEEE} Intelligent Vehicles Symposium},
	author = {Xu, Youchun and Zhao, Ming and Wang, Xiao and Zhang, Yongjin and Peng, Yongshen and Yuan, Yi and Liu, Hongquan},
	year = {2009},
	keywords = {automated highways, cell partition, Image motion analysis, image symmetrical move, intelligent vehicle environment, Intelligent vehicles, lane marker, Laser radar, object detection, obstacle detection, Partitioning algorithms, perspective projection model, Radar detection, road vehicles, stereo image processing, stereo obstacle detection, stereo vision, Testing, Transportation, Vehicle detection, Vehicle safety},
	pages = {36--41},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\HM9EGSFQ\\articleDetails.html:text/html}
}

@article{artieda_visual_2009,
	title = {Visual 3-{D} {SLAM} from {UAVs}},
	volume = {55},
	issn = {0921-0296, 1573-0409},
	doi = {10.1007/s10846-008-9304-8},
	abstract = {The aim of the paper is to present, test and discuss the implementation of Visual {SLAM} techniques to images taken from Unmanned Aerial Vehicles ({UAVs}) outdoors, in partially structured environments. Every issue of the whole process is discussed in order to obtain more accurate localization and mapping from {UAVs} flights. Firstly, the issues related to the visual features of objects in the scene, their distance to the {UAV}, and the related image acquisition system and their calibration are evaluated for improving the whole process. Other important, considered issues are related to the image processing techniques, such as interest point detection, the matching procedure and the scaling factor. The whole system has been tested using the {COLIBRI} mini {UAV} in partially structured environments. The results that have been obtained for localization, tested against the {GPS} information of the flights, show that Visual {SLAM} delivers reliable localization and mapping that makes it suitable for some outdoors applications when flying {UAVs}.},
	language = {en},
	number = {4-5},
	urldate = {2013-11-18},
	journal = {Journal of Intelligent and Robotic Systems},
	author = {Artieda, Jorge and Sebastian, José M. and Campoy, Pascual and Correa, Juan F. and Mondragón, Iván F. and Martínez, Carol and Olivares, Miguel},
	month = aug,
	year = {2009},
	keywords = {3D {SLAM}, Artificial Intelligence (incl. Robotics), computer vision, Control , Robotics, Mechatronics, Electrical Engineering, Mechanical Engineering, Unmanned Aerial Vehicles ({UAV}), Visual {SLAM}},
	pages = {299--321},
	file = {Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\R5E9P8C3\\10.html:text/html}
}

@article{pinies_large-scale_2008,
	title = {Large-Scale {SLAM} Building Conditionally Independent Local Maps: Application to Monocular Vision},
	volume = {24},
	issn = {1552-3098},
	shorttitle = {Large-Scale {SLAM} Building Conditionally Independent Local Maps},
	doi = {10.1109/TRO.2008.2004636},
	abstract = {Simultaneous localization and mapping ({SLAM}) algorithms based on local maps have been demonstrated to be well suited for mapping large environments as they reduce the computational cost and improve the consistency of the final estimation. The main contribution of this paper is a novel submapping technique that does not require independence between maps. The technique is based on the intrinsic structure of the {SLAM} problem that allows the building of submaps that can share information, remaining conditionally independent. The resulting algorithm obtains local maps in constant time during the exploration of new terrain and recovers the global map in linear time after simple loop closures without introducing any approximations besides the inherent extended Kalman filter linearizations. The memory requirements are also linear with the size of the map. As the algorithm works in a covariance form, well-known data-association techniques can be used in the usual manner. We present experimental results using a handheld monocular camera, building a map along a closed-loop trajectory of 140 m in a public square, with people and other clutter. Our results show that the combination of conditional independence, which enables the system to share the camera and feature states between submaps, and local coordinates, which reduce the effects of linearization errors, allow us to obtain precise maps of large areas with pure monocular {SLAM} in real time.},
	number = {5},
	journal = {{IEEE} Transactions on Robotics},
	author = {Pinies, P. and Tardos, J.D.},
	year = {2008},
	keywords = {closed loop systems, closed-loop trajectory, conditionally independent local map, covariance matrices, covariance matrix, data association technique, extended Kalman filter linearization, handheld monocular camera, Kalman filters, linearisation techniques, Local maps, loop closing, mobile robot, mobile robots, monocular vision, nonlinear filters, path planning, robot vision, scalability, sensor fusion, simultaneous localization and mapping ({SLAM}), simultaneous localization and mapping algorithm, {SLAM}, {SLAM} (robots), submapping technique, Visual {SLAM}},
	pages = {1094--1106},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\UHE5HH8H\\login.html:text/html}
}

@misc{_cgiar-csi_????,
	title = {{CGIAR}-{CSI} {SRTM} 90m {DEM} Digital Elevation Database},
	url = {http://srtm.csi.cgiar.org/},
	urldate = {2013-06-02},
	file = {CGIAR-CSI SRTM 90m DEM Digital Elevation Database:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\NGEDNW6F\\srtm.csi.cgiar.org.html:text/html}
}

@misc{center_for_history_and_new_media_zotero_????,
	title = {Zotero Quick Start Guide},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}}
}

@book{bar-shalom_estimation_2001,
	title = {Estimation with Applications to Tracking and Navigation: Theory Algorithms and Software},
	isbn = {978-0-471-41655-5},
	publisher = {Wiley},
	author = {Bar-Shalom, Yaakov and Li, X. Rong and Kirubarajan, Thiagalingam},
	month = jun,
	year = {2001}
}

@inproceedings{amzajerdian_lidar_2011,
	title = {Lidar Systems for Precision Navigation and Safe Landing on Planetary Bodies},
	volume = {819202},
	doi = {10.1117/12.904062},
	abstract = {The ability of lidar technology to provide three-dimensional elevation maps of the terrain, high precision distance to the ground, and approach velocity can enable safe landing of robotic and manned vehicles with a high degree of precision. Currently, {NASAis} developing novel lidar sensors aimed at the needs of future planetary landing missions.These lidar sensors are a 3-Dimensional Imaging Flash Lidar, a Doppler Lidar, and a Laser Altimeter. The Flash Lidar is capable of generating elevation maps of theterrain toindicate hazardous features such as rocks, craters, and steep slopes. The elevation maps, which arecollected during the approach phase of a landing vehicle from about 1 km above the ground, can be used to determine the most suitable safe landing site. The Doppler Lidar provides highly accurate ground relative velocity and distance data thusenablingprecision navigation to the landing site. Our Doppler lidar utilizes three laser beams that are pointed indifferent directions to measure line-of-sight velocities and ranges to the ground from altitudes of over 2 km.Starting at altitudes of about 20km and throughout the landing trajectory,the Laser Altimeter can provide very accurate ground relative altitude measurements that are used to improve the vehicle position knowledge obtained from the vehicle'snavigation system. Betweenaltitudesof approximately 15 km and 10 km, either the Laser Altimeter or the Flash Lidar can be used to generate contour maps of the terrain, identifying known surface features such as craters to perform Terrain relative Navigation thus further reducing the vehicle's relative position error. This paper describes the operational capabilities of each lidar sensorand provides a status of their development.},
	urldate = {2013-09-26},
	booktitle = {Proceedings of {SPIE} 8192,  International Symposium on Photoelectronic Detection and Imaging},
	author = {Amzajerdian, Farzin and Pierrottet, Diego and Petway, Larry and Hines, Glenn and Roback, Vincent},
	year = {2011}
}

@inproceedings{julier_counter_2001,
	title = {A Counter Example to the Theory of Simultaneous Localization and Map Building},
	volume = {4},
	doi = {10.1109/ROBOT.2001.933280},
	abstract = {The paper analyzes the properties of the full covariance simultaneous localization and map building problem ({SLAM}). We prove that, even for the special case of a stationary vehicle (with no process noise) which uses a range-bearing sensor and has non-zero angular uncertainty, the full covariance {SLAM} algorithm always yields an inconsistent map. We also show, through simulations, that these conclusions appear to extend to a moving vehicle with process noise. However, these inconsistencies only become apparent after several hundred beacon updates.},
	booktitle = {Proceedings of the {IEEE} International Conference on Robotics and Automation},
	author = {Julier, S.J. and Uhlmann, J.K.},
	year = {2001},
	keywords = {Acoustic noise, Analysis of variance, automatic guided vehicles, beacon updates, Buildings, Counting circuits, covariance matrices, Jacobian matrices, Laboratories, moving vehicle, path planning, process noise, range-bearing sensor, simultaneous localization and map building, Simultaneous localization and mapping, stationary vehicle, Stochastic processes, Vehicles, Virtual reality, Working environment noise},
	pages = {4238--4243},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\9INNRT7I\\login.html:text/html}
}

@inproceedings{okutomi_multiple-baseline_1991,
	title = {A Multiple-Baseline Stereo},
	doi = {10.1109/CVPR.1991.139662},
	abstract = {A stereo matching method is presented which uses multiple stereo pairs with various baselines to obtain precise depth estimates without suffering from ambiguity. The stereo matching method uses multiple stereo pairs with different baselines generated by a lateral displacement of a camera. Matching is performed by computing the sum of squared-difference ({SSD}) values. The {SSD} functions for individual stereo pairs are represented with respect to the inverse depth (rather than the disparity, as is usually done), and then are simply added to produce the sum of {SSDs}. This resulting function is called the {SSSD}-in-inverse-depth. The authors define a stereo algorithm, based on the {SSSD}-in-inverse-depth and then present a mathematical analysis to show how the algorithm can remove ambiguity and increase precision. Experimental results for stereo images are presented to demonstrate the effectiveness of the algorithm},
	booktitle = {Proceeding of the {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Okutomi, M. and Kanade, T.},
	year = {1991},
	keywords = {camera, Cameras, computer vision, computerised pattern recognition, computerised picture processing, Computerized monitoring, depth estimates, Filtering, Information systems, inverse depth, lateral displacement, Layout, Matched filters, mathematical analysis, multiple stereo pairs, multiple-baseline stereo, Pattern matching, {SSD} functions, stereo algorithm, stereo matching, stereo vision, sum of squared-difference, {US} Department of Defense},
	pages = {63--69},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\JN5DNVPT\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\UJ4EGMRU\\Okutomi and Kanade - 1991 - A multiple-baseline stereo.pdf:application/pdf}
}

@inproceedings{xiang_brief_2011,
	title = {A Brief Review on Visual Tracking Methods},
	doi = {10.1109/IVSurv.2011.6157020},
	abstract = {Long-term robust visual tracking is still a challenge, primarily due to the appearance changes of the scene and target. In this paper, we briefly review the recent progress in image representation, appearance model and motion model for building a general tracking system. The models reviewed here are basic enough to be applicable for tracking either single target or multiple targets. Special attention has been paid to the on-line adaptation of appearance model, a hot topic in the recent. Its key techniques have been discussed, such as classifier issue, on-line manner, sample selection and drifting problem. We notice that the recent state-of-the-art performances are generally given by a class of on-line boosting methods or `tracking-by-detection' methods (e.g. {OnlineBoost}, {SemiBoost}, {MIL}-Track, {TLD}, etc.). Therefore, we validate them together with typical traditional methods (e.g. template matching, Mean Shift, optical flow, particle filter, {FragTrack}) on a challenging sequence for single person tracking. Qualitative comparison results are presented.},
	booktitle = {Proceedings of the Third Chinese Conference on Intelligent Visual Surveillance ({IVS})},
	author = {Xiang, Xiang},
	year = {2011},
	keywords = {adaptation, Adaptation models, appearance, appearance model on-line adaptation, Boosting, drifting problem, Histograms, Image color analysis, image representation, image sampling, long-term robust visual tracking, motion, object detection, on-line boosting methods, Robustness, sample selection, single person tracking, Target tracking, Tracking, tracking-by-detection methods},
	pages = {41--44},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\7UUJKN4Q\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\ZDB442MG\\Xiang - 2011 - A brief review on visual tracking methods.pdf:application/pdf}
}

@inproceedings{huang_analysis_2008,
	title = {Analysis and Improvement of the Consistency of Extended {Kalman} Filter Based {SLAM}},
	doi = {10.1109/ROBOT.2008.4543252},
	abstract = {In this work, we study the inconsistency of {EKF}- based {SLAM} from the perspective of observability. We analytically prove that when the Jacobians of the state and measurement models are evaluated at the latest state estimates during every time step, the linearized error-state system model of the {EKF}- based {SLAM} has observable subspace of dimension higher than that of the actual, nonlinear, {SLAM} system. As a result, the covariance estimates of the {EKF} undergo reduction in directions of the state space where no information is available, which is a primary cause of inconsistency. To address this issue, a new "first estimates Jacobian" ({FEJ}) {EKF} is proposed, which is shown to perform better in terms of consistency. In the {FEJ}- {EKF}, the filter Jacobians are calculated using the first-ever available estimates for each state variable, which insures that the observable subspace of the error-state system model is of the same dimension as that of the underlying nonlinear {SLAM} system. The theoretical analysis is validated through extensive simulations.},
	booktitle = {Proceedings of the {IEEE} International Conference on Robotics and Automation},
	author = {Huang, Guoquan P. and Mourikis, A.I. and Roumeliotis, S.I.},
	year = {2008},
	keywords = {Computer science, extended Kalman filter, Filters, first estimates Jacobian, Jacobian matrices, Kalman filters, linearized error-state system model, Observability, Robotics and automation, Robots, Simultaneous localization and mapping, {SLAM}, {SLAM} (robots), state estimation, Time measurement, {USA} Councils},
	pages = {473--479},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\CDPCFBZN\\login.html:text/html}
}

@article{mir_definition_2012,
	title = {On the Definition of Radar Range Resolution for Targets of Greatly Differing {RCS}},
	volume = {61},
	issn = {0018-9456},
	doi = {10.1109/TIM.2011.2170371},
	abstract = {Conventional radar system design uses only waveform bandwidth to measure the range resolution. This paper examines the effect of both bandwidth and the difference in target radar cross section on range resolution. In the context of the subject scenario, the nature of the pulse-compressed return is studied, and a commonly used measurement definition of range resolution that assumes equally reflective targets is extended to account for the difference in target reflectivity as well. Results are presented as an application of the derived results to depict how resolution performance is affected by various parameters and how a more comprehensive definition of range resolution can be used during the system design.},
	number = {3},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Mir, H.S. and Carlson, B.D.},
	year = {2012},
	keywords = {Measurement, object detection, pulse-compressed return, Radar, Radar cross section, radar cross section ({RCS}), radar cross-sections, radar range resolution, radar resolution, radar system design, range resolution, {RCS}, Receivers, resolution bound, Signal resolution, target radar cross section, target reflectivity, unequal targets, waveform bandwidth, Wideband},
	pages = {655--663},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\KVQUVHKX\\login.html:text/html}
}

@inproceedings{zhang_obstacle_2012,
	title = {Obstacle Detection for Low Flying {UAS} Using Monocular Camera},
	doi = {10.1109/I2MTC.2012.6229318},
	abstract = {This paper describes an obstacle detection algorithm for low flying unmanned aircraft system ({UAS}) using an inertial aided inverse depth Extended Kalman Filter ({EKF}) framework. The {EKF} framework fuses inertial measurements with monocular image sensor measurements to estimate the positions of a number of landmarks as well as the position and orientation of the {UAS}. A high resolution sparse terrain elevation map and {UAS} trajectory can then be computed from the filter state vector. An inverse depth parameterization is used to describe the position of the landmarks so that features at all ranges can be tracked by the filter. A test flight was conducted to test the algorithm in a realistic scenario. The result shows that the algorithm produces accurate terrain elevation model, and is capable of generating accurate high resolution terrain elevation map when image sensor with high resolution and dynamic range is used.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Zhang, F. and Goubran, R. and Straznicky, P.},
	year = {2012},
	keywords = {Aircraft, Cameras, {EKF} framework, feature extraction, Feature extraction, filter state vector, Filters, Geophysical measurements, Global Positioning System, Heuristic algorithms, high resolution sparse terrain elevation map, Image resolution, image sensors, inertial aided inverse depth extended Kalman filter framework, inertial measurements, inverse depth parameterization, Kalman filters, low flying {UAS}, low flying unmanned aircraft system, monocular camera, monocular image sensor measurements, Motion Stereo, nonlinear filters, obstacle detection, obstacle detection algorithm, Range Estimate, terrain elevation model, test flight, {UAS}, Vectors},
	pages = {2133--2137},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\DWTQB4Z5\\articleDetails.html:text/html}
}

@misc{lemmens_airborne_2007,
	title = {Airborne {LiDAR} Sensors},
	url = {http://gim-international.com/files/productsurvey_v_pdfdocument_11.pdf},
	publisher = {{GIM} International},
	author = {Lemmens, Mathias},
	month = feb,
	year = {2007}
}

@phdthesis{bailey_mobile_2002,
	title = {Mobile Robot Localisation and Mapping in Extensive Outdoor Environments},
	abstract = {This thesis addresses the issues of scale for practical implementations of simultaneous localisation and mapping ({SLAM}) in extensive outdoor environments. Building an incremental map while also using it for localisation is of prime importance for mobile robot navigation but, until recently, has been confined to small-scale, mostly indoor, environments. The critical problems for large-scale implementations are as follows. First, data association--- finding correspondences between map landmarks and robot sensor measurements---becomes difficult in complex, cluttered environments, especially if the robot location is uncertain. Second, the information required to maintain a consistent map using traditional methods imposes a prohibitive computational burden as the map increases in size. And third, the mathematics for {SLAM} relies on assumptions of small errors and near-linearity, and these become invalid for larger maps.},
	school = {University of Sydney},
	author = {Bailey, Tim},
	year = {2002},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\FZ3EP2TG\\Bailey - 2002 - Mobile Robot Localisation and Mapping in Extensive.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\S48KND8I\\summary.html:text/html}
}

@article{matthies_kalman_1989,
	title = {Kalman Filter-Based Algorithms for Estimating Depth from Image Sequences},
	volume = {3},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1007/BF00133032},
	doi = {10.1007/BF00133032},
	abstract = {Using known camera motion to estimate depth from image sequences is an important problem in robot vision. Many applications of depth-from-motion, including navigation and manipulation, require algorithms that can estimate depth in an on-line, incremental fashion. This requires a representation that records the uncertainty in depth estimates and a mechanism that integrates new measurements with existing depth estimates to reduce the uncertainty over time. Kalman filtering provides this mechanism. Previous applications of Kalman filtering to depth-from-motion have been limited to estimating depth at the location of a sparse set of features. In this paper, we introduce a new, pixel-based (iconic) algorithm that estimates depth and depth uncertainty at each pixel and incrementally refines these estimates over time. We describe the algorithm and contrast its formulation and performance to that of a feature-based Kalman filtering algorithm. We compare the performance of the two approaches by analyzing their theoretical convergence rates, by conducting quantitative experiments with images of a flat poster, and by conducting qualitative experiments with images of a realistic outdoor-scene model. The results show that the new method is an effective way to extract depth from lateral camera translations. This approach can be extended to incorporate general motion and to integrate other sources of information, such as stereo. The algorithms we have developed, which combine Kalman filtering with iconic descriptions of depth, therefore can serve as a useful and general framework for low-level dynamic vision.},
	language = {en},
	number = {3},
	urldate = {2013-11-26},
	journal = {International Journal of Computer Vision},
	author = {Matthies, Larry and Kanade, Takeo and Szeliski, Richard},
	month = sep,
	year = {1989},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, Image processing},
	pages = {209--238},
	file = {Kalman filter-based algorithms for estimating depth from image se.pdf:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\SI5BRM7C\\Kalman filter-based algorithms for estimating depth from image se.pdf:application/pdf;Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\VSFSA6F9\\BF00133032.html:text/html}
}

@article{saad_robust_2011,
	title = {Robust High-Accuracy Ultrasonic Range Measurement System},
	volume = {60},
	issn = {0018-9456},
	doi = {10.1109/TIM.2011.2128950},
	abstract = {This paper presents a novel method for ultrasonic range estimation. The method uses a wideband frequency-hop spread spectrum ultrasonic signal to increase robustness to noise and reverberation. The method applies cross-correlation with earliest peak search and a novel minimum variance search technique to correct the error in the cross-correlation time-of-flight estimate to within one wavelength of the carrier before applying a phase-shift technique for subwavelength range refinement. The method can be implemented digitally in software and only requires low-cost hardware for signal transmission and acquisition. Experimental results show an accuracy of better than 0.5 mm in a typical office environment.},
	number = {10},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Saad, M. M. and Bleakley, Chris J. and Dobson, Simon},
	year = {2011},
	keywords = {Accuracy, Acoustics, correlation theory, cross-correlation, distance measurement, estimation, frequency hop communication, frequency hop spread spectrum, frequency-hop spread spectrum ({FHSS}), Noise, phase shift, phase shift technique, range estimation, Receivers, reverberation, signal acquisition, signal detection, signal transmission, spread spectrum communication, subwavelength range refinement, time of flight estimate, Transmitters, ultrasonic, ultrasonic measurement, ultrasonic range measurement, Ultrasonic variables measurement},
	pages = {3334--3341},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\MSIX37R6\\login.html:text/html}
}

@article{civera_inverse_2008,
	title = {Inverse Depth Parametrization for Monocular {SLAM}},
	volume = {24},
	issn = {1552-3098},
	doi = {10.1109/TRO.2008.2003276},
	abstract = {We present a new parametrization for point features within monocular simultaneous localization and mapping ({SLAM}) that permits efficient and accurate representation of uncertainty during undelayed initialization and beyond, all within the standard extended Kalman filter ({EKF}). The key concept is direct parametrization of the inverse depth of features relative to the camera locations from which they were first viewed, which produces measurement equations with a high degree of linearity. Importantly, our parametrization can cope with features over a huge range of depths, even those that are so far from the camera that they present little parallax during motion—maintaining sufficient representative uncertainty that these points retain the opportunity to "come in” smoothly from infinity if the camera makes larger movements. Feature initialization is undelayed in the sense that even distant features are immediately used to improve camera motion estimates, acting initially as bearing references but not permanently labeled as such. The inverse depth parametrization remains well behaved for features at all stages of {SLAM} processing, but has the drawback in computational terms that each point is represented by a 6-D state vector as opposed to the standard three of a Euclidean {XYZ} representation. We show that once the depth estimate of a feature is sufficiently accurate, its representation can safely be converted to the Euclidean {XYZ} form, and propose a linearity index that allows automatic detection and conversion to maintain maximum efficiency—only low parallax features need be maintained in inverse depth form for long periods. We present a real-time implementation at 30 Hz, where the parametrization is validated in a fully automatic 3-D {SLAM} system featuring a handheld single camera with no additional sensing. Experiments show robust operation in challenging indoor and outdoor environments with a very large ranges of scene depth, varied motion, and als- - o real time 360deg loop closing.},
	number = {5},
	journal = {{IEEE} Transactions on Robotics},
	author = {Civera, J. and Davison, A.J. and Montiel, J.},
	year = {2008},
	keywords = {camera motion estimates, extended Kalman filter, feature initialization, image sensors, inverse depth parametrization, Kalman filters, monocular simultaneous localization and mapping, Monocular simultaneous localization and mapping ({SLAM}), monocular {SLAM}, motion estimation, nonlinear filters, real-time vision, {SLAM} (robots)},
	pages = {932--945},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GFXCNBTW\\login.html:text/html}
}

@inproceedings{boberg_robocentric_2009,
	title = {Robocentric Mapping and Localization in Modified Spherical Coordinates with Bearing Measurements},
	doi = {10.1109/ISSNIP.2009.5416769},
	abstract = {In this paper, a new approach to robotic mapping is presented that uses modified spherical coordinates in a robot-centered reference frame and a bearing-only measurement model. The algorithm provided in this paper permits robust delay-free state initialization and is computationally more efficient than the current standard in bearing-only (delay-free initialized) simultaneous localization and mapping ({SLAM}). Importantly, we provide a detailed nonlinear observability analysis which shows the system is generally observable. We also analyze the error convergence of the filter using stochastic stability analysis. We provide an explicit bound on the asymptotic mean state estimation error. A comparison of the performance of this filter is also made against a standard world-centric {SLAM} algorithm in a simulated environment.},
	booktitle = {Proceedings of the 5th International Conference on Intelligent Sensors, Sensor Networks and Information Processing ({ISSNIP})},
	author = {Boberg, A. and Bishop, A.N. and Jensfelt, P.},
	year = {2009},
	keywords = {bearing measurements, Convergence, Coordinate measuring machines, Delay, delays, Error analysis, error convergence, Filters, machine bearings, modified spherical coordinates, nonlinear observability analysis, Observability, robocentric localization, robot centered reference, Robot kinematics, robust delay free state initialization, Robustness, Simultaneous localization and mapping, {SLAM} (robots), stability, standard world centric, state error estimation, Stochastic processes, stochastic stability analysis, stochastic systems},
	pages = {139--144},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\CD3GPU2U\\articleDetails.html:text/html}
}

@book{analytic_sciences_corporation_applied_1974,
	address = {Cambridge, Mass},
	title = {Applied Optimal Estimation},
	isbn = {0262200279},
	publisher = {M.I.T. Press},
	author = {{Analytic Sciences Corporation}},
	collaborator = {Gelb, Arthur},
	year = {1974},
	keywords = {Estimation theory, Mathematical optimization, System analysis}
}

@inproceedings{maier_self-supervised_2011,
	title = {Self-supervised Obstacle Detection for Humanoid Navigation Using Monocular Vision and Sparse Laser Data},
	doi = {10.1109/ICRA.2011.5979661},
	abstract = {In this paper, we present an approach to obstacle detection for collision-free, efficient humanoid robot navigation based on monocular images and sparse laser range data. To detect arbitrary obstacles in the surroundings of the robot, we analyze 3D data points obtained from a 2D laser range finder installed in the robot's head. Relying only on this laser data, however, can be problematic. While walking, the floor close to the robot's feet is not observable by the laser sensor, which inherently increases the risk of collisions, especially in nonstatic scenes. Furthermore, it is time-consuming to frequently stop walking and tilting the head to obtain reliable information about close obstacles. We therefore present a technique to train obstacle detectors for images obtained from a monocular camera also located in the robot's head. The training is done online based on sparse laser data in a self-supervised fashion. Our approach projects the obstacles identified from the laser data into the camera image and learns a classifier that considers color and texture information. While the robot is walking, it then applies the learned classifiers to the images to decide which areas are traversable. As we illustrate in experiments with a real humanoid, our approach enables the robot to reliably avoid obstacles during navigation. Furthermore, the results show that our technique leads to significantly more efficient navigation compared to extracting obstacles solely based on 3D laser range data acquired while the robot is standing at certain intervals.},
	booktitle = {Proceedings of the {IEEE} International Conference on Robotics and Automation},
	author = {Maier, D. and Bennewitz, M. and Stachniss, C.},
	year = {2011},
	keywords = {arbitrary obstacle detection, close obstacles, collision avoidance, color information, control engineering computing, humanoid robot navigation, humanoid robots, Lasers, Legged locomotion, monocular images, monocular vision, Navigation, robot feet, robot head, Robot sensing systems, robot vision, self-supervised obstacle detection, sparse laser range data, texture information, Three dimensional displays},
	pages = {1263--1269},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\KMCZMTWR\\articleDetails.html:text/html}
}

@inproceedings{jepson_fast_1991,
	title = {A Fast Subspace Algorithm for Recovering Rigid Motion},
	doi = {10.1109/WVM.1991.212779},
	abstract = {The image motion field for an observer moving through a static environment depends on the observer's translational and rotational velocities along with the distances to surface points. Given such a motion field as input the authors present a new algorithm for computing the observer's motion and the depth structure of the scene. The approach is a further development of sub-space methods. This class of methods involve splitting the equations describing the motion field into separate equations for the observer's translational direction, the rotational velocity and the relative depths. The resulting equations can then be solved successively, beginning with the equations for the translational direction. The authors show how this first step can be simplified considerably. The consequence is that the observer's velocity and the relative depths to points in the scene can all be recovered by successively solving three linear problems},
	booktitle = {Proceedings of the {IEEE} Workshop on Visual Motion},
	author = {Jepson, A.D. and Heeger, D.J.},
	year = {1991},
	keywords = {Angular velocity, Cameras, depth structure, egomotion recovery, Equations, fast subspace algorithm, Fluid flow measurement, Image motion analysis, image motion field, Layout, Motion analysis, motion estimation, Motion measurement, moving observer, relative depths, rigid motion, rotational velocities, rotational velocity, Sampling methods, static environment, surface points, translational velocities, Vectors},
	pages = {124--131},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\B8JRGZNK\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\BFVZHQCW\\Jepson and Heeger - 1991 - A fast subspace algorithm for recovering rigid mot.pdf:application/pdf}
}

@inproceedings{tsai_efficient_1986,
	title = {An Efficient and Accurate Camera Calibration Technique for {3D} Machine Vision},
	booktitle = {Proceedings of the {IEEE} Conference on Computer Vision and Pattern Recognition},
	author = {Tsai, R.Y.},
	year = {1986},
	pages = {364--374}
}

@article{bailey_simultaneous_2006,
	title = {Simultaneous Localization and Mapping ({SLAM}): Part {II}},
	volume = {13},
	issn = {1070-9932},
	shorttitle = {Simultaneous localization and mapping ({SLAM})},
	doi = {10.1109/MRA.2006.1678144},
	abstract = {This paper discusses the recursive Bayesian formulation of the simultaneous localization and mapping ({SLAM}) problem in which probability distributions or estimates of absolute or relative locations of landmarks and vehicle pose are obtained. The paper focuses on three key areas: computational complexity; data association; and environment representation},
	number = {3},
	journal = {{IEEE} Robotics Automation Magazine},
	author = {Bailey, Tim and Durrant-Whyte, H.},
	year = {2006},
	keywords = {Bayes methods, Bayesian methods, computational complexity, Computational efficiency, data association, Delay estimation, environment representation, mobile robot, mobile robots, path planning, probability distributions, recursive Bayesian formulation, Robotics and automation, Robustness, Simultaneous localization and mapping, statistical distributions, Uncertainty, vehicle pose, Vehicles},
	pages = {108--117},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\5KS3MMZN\\abs_all.html:text/html}
}

@article{dissanayake_solution_2001,
	title = {A Solution to the Simultaneous Localization and Map Building ({SLAM}) Problem},
	volume = {17},
	issn = {1042-296X},
	doi = {10.1109/70.938381},
	abstract = {The simultaneous localization and map building ({SLAM}) problem asks if it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and then to incrementally build a map of this environment while simultaneously using this map to compute absolute vehicle location. Starting from estimation-theoretic foundations of this problem, the paper proves that a solution to the {SLAM} problem is indeed possible. The underlying structure of the {SLAM} problem is first elucidated. A proof that the estimated map converges monotonically to a relative map with zero uncertainty is then developed. It is then shown that the absolute accuracy of the map and the vehicle location reach a lower bound defined only by the initial vehicle uncertainty. Together, these results show that it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and, using relative observations only, incrementally build a perfect map of the world and to compute simultaneously a bounded estimate of vehicle location. The paper also describes a substantial implementation of the {SLAM} algorithm on a vehicle operating in an outdoor environment using millimeter-wave radar to provide relative map observations. This implementation is used to demonstrate how some key issues such as map management and data association can be handled in a practical environment. The results obtained are cross-compared with absolute locations of the map landmarks obtained by surveying. In conclusion, the paper discusses a number of key issues raised by the solution to the {SLAM} problem including suboptimal map-building algorithms and map management},
	number = {3},
	journal = {{IEEE} Transactions on Robotics and Automation},
	author = {Dissanayake, M. W M G and Newman, P. and Clark, S. and Durrant-Whyte, H.F. and Csorba, M.},
	year = {2001},
	keywords = {absolute accuracy, absolute vehicle location, autonomous vehicle, covariance matrices, Environmental management, Estimation theory, estimation-theoretic foundations, filtering theory, Helium, map management, Mechatronics, Millimeter wave radar, millimeter-wave radar, mobile robots, motion planning, Navigation, outdoor environment, path planning, perfect map, relative map, Remotely operated vehicles, simultaneous localization and map building problem, Simultaneous localization and mapping, {SLAM} problem, state estimation, suboptimal map-building algorithms, Uncertainty, unknown environment, unknown location},
	pages = {229--241},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\IBWKX22A\\login.html:text/html}
}

@article{durrant-whyte_uncertain_1988,
	title = {Uncertain Geometry in Robotics},
	volume = {4},
	issn = {0882-4967},
	doi = {10.1109/56.768},
	abstract = {The author suggests that to operate efficiently, a robot system must be able to represent, account for, and reason about the effects of uncertainty in areas in which geometric analysis also plays an important part. He proposed that uncertainty be represented as an intrinsic part of all geometric descriptions. Toward this goal he develops a description of uncertain geometric features as families of parametrized functions together with a distribution function defined on the associated parameter vector. Uncertain points, curves, and surfaces are considered, and it is shown how they can be manipulated and transformed between coordinate frames in an efficient and consistent manner. The effectiveness of these techniques is demonstrated by application to the problem of developing maximal-information sensing strategies},
	number = {1},
	journal = {{IEEE} Journal of Robotics and Automation},
	author = {Durrant-Whyte, H.F.},
	year = {1988},
	keywords = {Computational geometry, control system analysis, coordinate frames, decision theory, geometric descriptions, geometry, Manipulators, Measurement uncertainty, Motion analysis, motion planning, Robot kinematics, Robot sensing systems, robot system, Robotics and automation, Robots, Service robots, Solid modeling, uncertain geometry, Uncertainty},
	pages = {23--31},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\EJ2I6RJ6\\login.html:text/html}
}

@article{bosse_slam_2004,
	title = {{SLAM} in Large-scale Cyclic Environments Using the {Atlas} Framework},
	abstract = {This paper describes Atlas, a hybrid metrical/topological approach to simultaneous localization and mapping ({SLAM}) that achieves efficient mapping of large-scale environments. The representation is a graph of coordinate frames, with each vertex in the graph representing a local frame and each edge representing the transformation between adjacent frames. In each frame, we build a map that captures the local environment and the current robot pose along with the uncertainties of each. Each map’s uncertainties are modeled with respect to its own frame. Probabilities of entities with respect to arbitrary frames are generated by following a path formed by the edges between adjacent frames, computed using either Dijkstra’s shortest path algorithm or breath-first search. Loop closing is achieved via an efficient map matching algorithm coupled with a cycle verification step. We demonstrate the performance of the technique for post-processing large data sets, including an indoor structured environment (2.2 km path length) with multiple nested loops using laser or ultrasonic ranging sensors. 1},
	journal = {International Journal of Robotics Research},
	author = {Bosse, Michael and Newman, Paul and Leonard, John and Teller, Seth},
	year = {2004},
	pages = {1113--1139},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\HWSPDWKX\\Bosse et al. - 2004 - SLAM in large-scale cyclic environments using the .pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\C96Q38VU\\summary.html:text/html}
}

@phdthesis{csorba_simultaneous_1997,
	title = {Simultaneous Localisation and Map Building},
	abstract = {This thesis examines the problem of localising an Autonomous Guided Vehicle ({AGV}) travelling in an unknown environment. In this problem, the {AGV} faces the dual task of modeling the environment and simultaneously localising its position within it. The Simultaneous Localisation and Map Building ({SLAM}) problem is currently one of the most important goals of {AGV} research. Solving this problem would allow {anAGV} to be deployed easily, with very little initial preparation. The {AGV} would also be exible and able to cope with modi cations in the environment. A solution to the {SLAM} problem would enable an {AGV} to would be truly {\textbackslash}autonomous." The thesis examines the {SLAM} problem from an estimation theoretic point ofview. The estimation approach provides a rigorous framework for the analysis and has also proven to be successful in actual applications. The most signi cant contribution of this thesis is to provide, for the rst time, a detailed development of the theory of the {SLAM} problem. It is shown that correlations arise between errors in the vehicle and the map estimates, and these correlations are identi ed as fundamentally important to the solution of the {SLAM} problem. It is demonstrated that ignoring these correlations results in the loss of the fundamental structure of the {SLAM} problem and leads to inconsistency in map},
	school = {University of Oxford},
	author = {Csorba, Michael},
	year = {1997},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\9RBGFNM7\\Csorba - 1997 - Simultaneous Localisation and Map Building.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\DXEE3PEN\\summary.html:text/html}
}

@inproceedings{zhao_large-scale_2010,
	title = {Large-scale Monocular {SLAM} by Local Bundle Adjustment and Map Joining},
	doi = {10.1109/ICARCV.2010.5707820},
	abstract = {This paper first demonstrates an interesting property of bundle adjustment ({BA}), “scale drift correction”. Here “scale drift correction” means that {BA} can converge to the correct solution (up to a scale) even if the initial values of the camera pose translations and point feature positions are calculated using very different scale factors. This property together with other properties of {BA} makes it the best approach for monocular Simultaneous Localization and Mapping ({SLAM}), without considering the computational complexity. This naturally leads to the idea of using local {BA} and map joining to solve large-scale monocular {SLAM} problem, which is proposed in this paper. The local maps are built through Scale-Invariant Feature Transform ({SIFT}) for feature detection and matching, random sample consensus ({RANSAC}) paradigm at different levels for robust outlier removal, and {BA} for optimization. To reduce the computational cost of the large-scale map building, the features in each local map are judiciously selected and then the local maps are combined using a recently developed 3D map joining algorithm. The proposed large-scale monocular {SLAM} algorithm is evaluated using a publicly available dataset with centimeter-level ground truth.},
	booktitle = {Proceedings of the 11th International Conference on Control Automation Robotics Vision ({ICARCV})},
	author = {Zhao, Liang and Huang, Shoudong and Yan, Lei and Wang, J.J. and Hu, G. and Dissanayake, G.},
	year = {2010},
	keywords = {Barium, Buildings, bundle adjustment, Cameras, Computational efficiency, estimation, feature detection, feature extraction, Feature extraction, map joining, monocular {SLAM}, random sample consensus paradigm, scale invariant feature transform, Simultaneous localization and mapping, {SLAM} (robots), Three dimensional displays, Visual {SLAM}},
	pages = {431--436},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\AIPMUI9U\\articleDetails.html:text/html}
}

@inproceedings{shi_good_1994,
	title = {Good Features to Track},
	doi = {10.1109/CVPR.1994.323794},
	abstract = {No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments},
	booktitle = {Proceedings of the {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Shi, J. and Tomasi, C.},
	year = {1994},
	keywords = {affine image transformations, computer vision, disocclusions, feature extraction, Feature extraction, feature monitoring, feature selection, feature-based, Machine vision, Newton-Raphson style search methods, occlusions, performance, tracker, Tracking, vision system},
	pages = {593--600},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\QTMT8AC8\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GRBA9WKE\\Shi and Tomasi - 1994 - Good features to track.pdf:application/pdf}
}

@article{wooden_guide_2006,
	title = {A Guide to Vision-Based Map Building},
	volume = {13},
	issn = {1070-9932},
	doi = {10.1109/MRA.2006.1638021},
	abstract = {This paper describes a simple vision-based mapping system for mobile robot navigation in an unknown outdoor environment, consistent with the efforts of Georgia Tech's team for the {DARPA}-sponsored Learning Applied to Ground Robots ({LAGR}) project. This approach, which has been robust to different environments and responsive to time-critical constraints, is a good example of robotics in practice},
	number = {2},
	journal = {{IEEE} Robotics Automation Magazine},
	author = {Wooden, D.},
	year = {2006},
	keywords = {camera frames, Cameras, Computational geometry, coordinate transformations, cost maps, Global Positioning System, Hardware, Learning Applied to Ground Robots project, Linux, map building, mobile robot navigation, mobile robots, outdoor real-time robotics platform, Robot kinematics, Robot sensing systems, robot vision, Robot vision systems, Robotics and automation, stereo depth maps, Switches, unknown outdoor course, vision-based mapping system},
	pages = {94--98},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\2JNW7UIQ\\login.html:text/html}
}

@article{aidala_utilization_1983,
	title = {Utilization of Modified Polar Coordinates for Bearings-only Tracking},
	volume = {28},
	issn = {0018-9286},
	doi = {10.1109/TAC.1983.1103230},
	abstract = {Previous studies have shown that the Cartesian coordinate extended Kalman filter exhibits unstable behavior characteristics when utilized for bearings-only target motion analysis ({TMA}). In contrast, formulating the {TMA} estimation problem in modified polar ({MP}) coordinates leads to an extended Kalman filter which is both stable and asymptotically unbiased. Exact state equations for the {MP} filter are derived without imposing any restrictions on own-ship motion; thus, prediction accuracy inherent in the traditional Cartesian formulation is completely preserved. In addition, these equations reveal that {MP} coordinates are well-suited for bearings-only {TMA} because they automatically decouple observable and unobservable components of the estimated state vector. Such decoupling is shown to prevent covariance matrix ill-conditioning, which is the primary cause of filter instability. Further investigation also confirms that the {MP} state estimates are asymptotically unbiased. Realistic simulation data are presented to support these findings and to compare algorithm performance with respect to the Cramer-Rao lower bound (ideal) as well as the Cartesian and pseudolinear filters.},
	number = {3},
	journal = {{IEEE} Transactions on Automatic Control},
	author = {Aidala, V.J. and Hammel, S.E.},
	year = {1983},
	keywords = {Accuracy, covariance matrix, Decoupling of systems, Differential equations, Direction-of-arrival estimation, Filters, Government, Kalman filtering, nonlinear systems, Matrices, Motion analysis, Nonlinear equations, Sea measurements, Sonar tracking, state estimation, Target tracking, Tracking filters},
	pages = {283--294},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\APR2ZDFM\\Aidala and Hammel - 1983 - Utilization of modified polar coordinates for bear.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\2W5KBRAF\\Aidala and Hammel - 1983 - Utilization of modified polar coordinates for bear.pdf:application/pdf}
}

@article{frese_discussion_2006,
	title = {A Discussion of Simultaneous Localization and Mapping},
	volume = {20},
	issn = {0929-5593, 1573-7527},
	doi = {10.1007/s10514-006-5735-x},
	abstract = {This paper aims at a discussion of the structure of the {SLAM} problem. The analysis is not strictly formal but based both on informal studies and mathematical derivation. The first part highlights the structure of uncertainty of an estimated map with the key result being “Certainty of Relations despite Uncertainty of Positions”. A formal proof for approximate sparsity of so-called information matrices occurring in {SLAM} is sketched. It supports the above mentioned characterization and provides a foundation for algorithms based on sparse information matrices. Further, issues of nonlinearity and the duality between information and covariance matrices are discussed and related to common methods for solving {SLAM}. Finally, three requirements concerning map quality, storage space and computation time an ideal {SLAM} solution should have are proposed. The current state of the art is discussed with respect to these requirements including a formal specification of the term “map quality”.},
	language = {en},
	number = {1},
	urldate = {2013-09-15},
	journal = {Autonomous Robots},
	author = {Frese, Udo},
	month = jan,
	year = {2006},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, Electronic and Computer Engineering, estimation, information matrix, Mechanical Engineering, mobile robot, Navigation, Simulation and Modeling, Simultaneous localization and mapping, {SLAM}, Uncertainty},
	pages = {25--42},
	file = {Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GJKX8ZVT\\10.html:text/html}
}

@inproceedings{heikkila_four-step_1997,
	title = {A Four-Step Camera Calibration Procedure with Implicit Image Correction},
	doi = {10.1109/CVPR.1997.609468},
	abstract = {In geometrical camera calibration the objective is to determine a set of camera parameters that describe the mapping between 3-D reference coordinates and 2-D image coordinates. Various methods for camera calibration can be found from the literature. However surprisingly little attention has been paid to the whole calibration procedure, i.e., control point extraction from images, model fitting, image correction, and errors originating in these stages. The main interest has been in model fitting, although the other stages are also important. In this paper we present a four-step calibration procedure that is an extension to the two-step method. There is an additional step to compensate for distortion caused by circular features, and a step for correcting the distorted image coordinates. The image correction is performed with an empirical inverse model that accurately compensates for radial and tangential distortions. Finally, a linear method for solving the parameters of the inverse model is presented},
	booktitle = {Proceeding of the {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Heikkila, J. and Silven, O.},
	year = {1997},
	keywords = {Calibration, Camera calibration, Cameras, Closed-form solution, computer vision, Error correction, geometrical camera calibration, Geometrical optics, image correction, implicit image correction, inverse model, Inverse problems, Machine vision, Mathematical model, Minimization methods, model fitting, Nonlinear distortion, three-dimensional machine vision},
	pages = {1106--1112},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GJ84V4CQ\\login.html:text/html}
}

@inproceedings{hanna_obstacle_2008,
	title = {Obstacle Detection for Low Flying Unmanned Aerial Vehicles Using Stereoscopic Imaging},
	doi = {10.1109/IMTC.2008.4547014},
	abstract = {This paper describes a stereoscopic imaging algorithm that is modified for obstacle detection in low flying unmanned aerial vehicles ({UAVs}). In this type of flight, obstacle detection must be carried out quickly for the system to be effective in real time. Additionally, since the aircraft is close to the ground, the horizon is usually at the top of the field of view and obstacles must be distinguished from the clutter of the terrain. The sparse edge detection and reconstruction algorithm proposed, produces fast but partial reconstructions of the environment. One image is passed through a series of edge detectors to generate a very sparse outline of the environment. This outline is then correlated to the second image and the resulting reconstruction is added to a model of the environment. Although each individual reconstruction is incomplete, the overall result after a short initialization period is a model of the environment that is more comprehensive than a single stereoscopic correlation run with a more detailed edge detector. Simulation of the algorithm on test image patterns showed an increase in performance relative to the length of the sequence of stereo pairs. On average, the signal to noise ratio ({SNR}) for sparse edge reconstruction was significantly higher than that for single correlation with more detailed edge detectors. Additionally it was found that the processing speed of the sparse edge detection algorithm on a pair of stereoscopic images is faster than the processing carried out by a more detailed edge detector. A test flight was also carried out to test the algorithm in a more realistic scenario. The test confirmed that the sparse edge reconstruction algorithm resulted in a much more detailed view of the environment than if a single, more detailed edge detector had been used.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Hanna, E. and Straznicky, P. and Goubran, R.},
	year = {2008},
	keywords = {Aircraft, collision avoidance, computer vision, Detectors, distance measurement, edge detection, Image edge detection, image reconstruction, image sequence, image sequences, low flying unmanned aerial vehicles, obstacle detection, Obstacle Detection and Avoidance, Real time systems, Real-time Processing, Reconstruction algorithms, Remotely operated vehicles, Signal to noise ratio, sparse edge detection, stereo image processing, stereoscopic imaging, Testing, Unmanned aerial vehicles, Unmanned Aerial Vehicles ({UAV}), Vehicle detection},
	pages = {113--118},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\WHF3VXHQ\\login.html:text/html}
}

@misc{_world_????,
	title = {World Geodetic System - {Wikipedia}, the free encyclopedia},
	url = {https://en.wikipedia.org/wiki/World_Geodetic_System},
	urldate = {2013-06-02},
	file = {World Geodetic System - Wikipedia, the free encyclopedia:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\PV4H27F8\\World_Geodetic_System.html:text/html}
}

@inproceedings{yamaguchi_moving_2006,
	title = {Moving Obstacle Detection using Monocular Vision},
	doi = {10.1109/IVS.2006.1689643},
	abstract = {This paper proposes a method for detecting moving obstacles on roads, by using a vehicle mounted monocular camera. To detect various moving obstacles, such as vehicles and pedestrians, the ego-motion of the vehicle is initially estimated from images captured by the camera. There are two problems in ego-motion estimation. Firstly, a typical road scene contains moving obstacles. This causes false estimation of the ego-motion. Secondly, roads possess fewer features, when compared to the number associated with background structures. This reduces the accuracy of ego-motion estimation. In our approach, the ego-motion is estimated from the correspondences of dispersed feature points extracted from various regions other than those that contain moving obstacles. After estimating the ego-motion, any moving obstacles are detected by tracking the feature points over consecutive frames. In our experiments, it has been shown that the proposed method is able to detect moving obstacles},
	booktitle = {Proceedings of the {IEEE} Intelligent Vehicles Symposium},
	author = {Yamaguchi, K. and Kato, T. and Ninomiya, Y.},
	year = {2006},
	keywords = {Cameras, ego-motion estimation, feature extraction, Feature extraction, feature point extraction, Image motion analysis, Laser radar, Layout, monocular vision, motion estimation, moving obstacle detection, Nonlinear optics, object detection, Optical sensors, Radar detection, road vehicles, Robustness, traffic engineering computing, Vehicle detection},
	pages = {288--293},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\2JIKQF6H\\articleDetails.html:text/html}
}

@article{huang_convergence_2007,
	title = {Convergence and Consistency Analysis for Extended {Kalman} Filter Based {SLAM}},
	volume = {23},
	issn = {1552-3098},
	doi = {10.1109/TRO.2007.903811},
	abstract = {This paper investigates the convergence properties and consistency of extended Kalman filter ({EKF}) based simultaneous localization and mapping ({SLAM}) algorithms. Proofs of convergence are provided for the nonlinear two-dimensional {SLAM} problem with point landmarks observed using a range-and-bearing sensor. It is shown that the robot orientation uncertainty at the instant when landmarks are first observed has a significant effect on the limit and/or the lower bound of the uncertainties of the landmark position estimates. This paper also provides some insights to the inconsistencies of {EKF} based {SLAM} that have been recently observed. The fundamental cause of {EKF} {SLAM} inconsistency for two basic scenarios are clearly stated and associated theoretical proofs are provided.},
	number = {5},
	journal = {{IEEE} Transactions on Robotics},
	author = {Huang, Shoudong and Dissanayake, G.},
	year = {2007},
	keywords = {Algorithm design and analysis, Australia Council, consistency analysis, Convergence, extended information filter, extended Kalman filter, inconsistency, Information filters, Jacobian matrices, Kalman filters, landmark position estimates, nonlinear filters, nonlinear two-dimensional problem, path planning, range-and-bearing sensor, robot, Robot sensing systems, Robotics and automation, Robots, Simultaneous localization and mapping, simultaneous localization and mapping ({SLAM}), simultaneous localization and mapping algorithms, {SLAM}, state estimation, Uncertainty},
	pages = {1036--1049},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\DMA8EH8K\\login.html:text/html}
}

@inproceedings{nemra_robust_2010,
	title = {Robust Cooperative {UAV} Visual {SLAM}},
	doi = {10.1109/UKRICIS.2010.5898125},
	abstract = {This paper aims at proposing a framework for Airborne Cooperative Visual Simultaneous Localization and Mapping (C-{VSLAM}). The use of cooperative vehicles presents many advantages over single-vehicle architecture. We present a nonlinear H∞ filtering scheme adapted to multiple Unmanned Aerial Vehicle ({UAV}) {VSLAM} based on the extension of a robust single vehicle {VSLAM} solution. Loop closure concept, based on revisited features is described with feature uncertainty analysis. Comparisons between single and multiple {UAV} {VSLAM} are made using realistic simulation scenario.},
	booktitle = {Proceedings of the 9th {IEEE} International Conference on Cybernetic Intelligent Systems},
	author = {Nemra, A. and Aouf, N.},
	year = {2010},
	keywords = {airborne cooperative visual simultaneous localization and mapping, aircraft control, Cameras, cooperative systems, feature uncertainty, H∞ control, Jacobian matrices, loop closure, loop closure concept, mobile robots, multi-robot systems, Navigation, nonlinear control systems, nonlinear filters, Nonlinear H∞ filter, nonlinear H∞ filtering, Remotely operated vehicles, robot vision, robust control, robust cooperative {UAV}, Simultaneous localization and mapping, single vehicle architecture, {SLAM}, {SLAM} (robots), stereo vision, {UAV}, uncertainty analysis, unmanned aerial vehicle, Vehicles, Visual {SLAM}, Visualization},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\TEFME4XQ\\login.html:text/html}
}

@article{chong_feature-based_1999,
	title = {Feature-based Mapping in Real, Large Scale Environments using an Ultrasonic Array},
	volume = {18},
	abstract = {This paper presents a strategy for achieving practical mapping navigation using a wheeled  mobile robot equipped with an advanced sonar sensor. The original mapping navigation  experiment, carried out with the same robot configuration, builds a feature map consisting of  commonplace indoor landmarks crucial for localisation, namely planes, corners and edges. The  map exhaustively maintains covariance matrices among all features, thus presents a time and  memory impediment to practical navigation in large environments. The new local mapping  strategy proposed here breaks down a large environment into a topology of local regions, only  maintaining the covariance among features in the same local region, and the covariance among  local maps. This notion of two hierarchy representation drastically improves the memory and  processing time requirements of the original global approach, while preserving the statistical  details, in the authors' opinions, necessary for an accurate map and prolon...},
	number = {1},
	journal = {International Journal of Robotics Research},
	author = {Chong, Kok Seng and Kleeman, Lindsay},
	year = {1999},
	pages = {3--19},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\3B5J8IGP\\Chong and Kleeman - 1999 - Feature-based Mapping in Real, Large Scale Environ.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\SN5CP6G5\\summary.html:text/html}
}

@article{bouguet_pyramidal_1999,
	title = {Pyramidal Implementation of the {Lucas} {Kanade} Feature Tracker, Description of the Algorithm},
	journal = {Intel Corporation, Microprocessor Research Labs, {OpenCV} Documents},
	author = {Bouguet, J. Y},
	year = {1999}
}

@inproceedings{martinelli_results_2005,
	title = {Some Results on {SLAM} and the Closing the Loop Problem},
	doi = {10.1109/IROS.2005.1545003},
	abstract = {This paper addresses the closing loop problem as the challenge of using all the information from the observation gathered when closing the loop in order to optimally adjust the whole map (assuming a correct data association). The proposed approach is an approximation, which allows the calculation of the gain without keeping track of all the correlations (i.e. with a complexity independent of the number of the map elements). Furthermore, the paper presents an explicit mathematical demonstration showing that the correlations computed by the {EKF}-based {SLAM} are overestimated. More precisely, it is shown that these correlations decrease exponentially with respect to the heading error of the robot. The approach is empirically demonstrated by means of meaningful simulations. The results are then discussed and conclusions are pointed out in the last section.},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Martinelli, A. and Tomatis, N. and Siegwart, R.},
	year = {2005},
	keywords = {closed loop systems, Closing Loop Problem, closing the loop problem, computational complexity, Computational modeling, data association, extended Kalman filter, Kalman filter, Kalman filters, Layout, mobile robots, optimal control, Relative Observation, robot heading error, Robot sensing systems, sensor fusion, Sensor phenomena and characterization, Simultaneous localization and mapping, {SLAM}, Stochastic processes, Technological innovation},
	pages = {2917--2922},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\QV44ZVPK\\login.html:text/html}
}

@inproceedings{bailey_consistency_2006,
	title = {Consistency of the {EKF}-{SLAM} Algorithm},
	doi = {10.1109/IROS.2006.281644},
	abstract = {This paper presents an analysis of the extended Kalman filter formulation of simultaneous localisation and mapping ({EKF}-{SLAM}). We show that the algorithm produces very optimistic estimates once the "true" uncertainty in vehicle heading exceeds a limit. This failure is subtle and cannot, in general, be detected without ground-truth, although a very inconsistent filter may exhibit observable symptoms, such as disproportionately large jumps in the vehicle pose update. Conventional solutions - adding stabilising noise, using an iterated {EKF} or unscented filter, etc., - do not improve the situation. However, if "small" heading uncertainty is maintained, {EKF}-{SLAM} exhibits consistent behaviour over an extended time-period. Although the uncertainty estimate slowly becomes optimistic, inconsistency can be mitigated indefinitely by applying tactics such as batch updates or stabilising noise. The manageable degradation of small heading variance {SLAM} indicates the efficacy of submap methods for large-scale maps},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Bailey, Tim and Nieto, J. and Guivant, J. and Stevens, M. and Nebot, E.},
	year = {2006},
	keywords = {Australia, Context modeling, Degradation, extended Kalman filter, Filters, Intelligent robots, Kalman filters, large-scale maps, Large-scale systems, mobile robots, Probability distribution, simultaneous localisation and mapping, Simultaneous localization and mapping, {SLAM}, {SLAM} (robots), Uncertainty, Vehicles},
	pages = {3562--3568},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\A7IJUFCF\\login.html:text/html}
}

@article{laganiere_robust_2006,
	title = {Robust Object Pose Estimation from Feature-based Stereo},
	volume = {55},
	issn = {0018-9456},
	doi = {10.1109/TIM.2006.876521},
	abstract = {This paper addresses the problem of computing the three-dimensional (3-D) path of a moving rigid object using a calibrated stereoscopic vision setup. The proposed system begins by detecting feature points on the moving object. By tracking these points over time, it produces clouds of 3-D points that can be registered, thus giving information about the underlying camera motion. A novel correction scheme that compensates for the accumulated error in the computed positions by automatic detection of loop-back points in the movement of the object is also proposed. An application to object modeling is presented in which a handheld object is moved in front of a camera and is reconstructed using silhouette intersection.},
	number = {4},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Laganiere, R. and Gilbert, S. and Roth, G.},
	year = {2006},
	keywords = {3D path, 3D points, automatic detection, Calibration, Camera calibration, Cameras, computer vision, Design automation, Error correction, error correction scheme, feature matching, feature point detection, feature tracking, feature-based stereo, image reconstruction, Information technology, Layout, loop-back points, object detection, object pose estimation, pose estimation, Robot vision systems, Robustness, shape-from-silhouette, silhouette intersection, stereo image processing, stereoscopic vision, stereovision, three-dimensional (3-D) reconstruction},
	pages = {1270--1280},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\UCHPQAD2\\articleDetails.html:text/html}
}

@inproceedings{de_angelis_experimental_2008,
	title = {An Experimental {UWB} Distance Measurement System},
	doi = {10.1109/IMTC.2008.4547186},
	abstract = {This paper presents a distance-measuring system based on the accurate round-trip time-of-flight measurement of single ultra-wideband pulses, propagating between two transceiver devices. The architectures of two realized devices, referred to as master and slave, are described. The master device implements the time-interval measuring function, by means of a time-to-digital converter integrated circuit, while the slave acts as pulse repeater. Both devices are designed for low-cost realization and low-power operations. This paper also presents and discusses some experimental results obtained from the system prototype. Finally, some numerical simulations results are shown, which could provide an explanation for the non-idealities in the observed distance-measuring behaviour of the system.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology},
	author = {De Angelis, A. and Dionigi, M. and Moschitta, A. and Giglietti, R. and Carbone, P.},
	year = {2008},
	keywords = {accurate round-trip time-of-flight measurement, convertors, distance measurement, Integrated circuit measurements, integrated circuits, Master-slave, Numerical simulation, Prototypes, Pulse circuits, Pulse measurements, pulse repeater, Repeaters, round-trip-time, time-interval measuring function, time-to-digital converter integrated circuit, transceiver devices, transceivers, ultra wideband technology, ultra-wideband pulses, ultra-wideband ranging, {UWB} distance measurement system},
	pages = {1016--1020},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\33A7I7IG\\login.html:text/html}
}

@misc{_pyproj_????,
	title = {pyproj - {Python} Interface to {PROJ}.4 Library},
	url = {http://code.google.com/p/pyproj/},
	urldate = {2013-06-02},
	file = {pyproj - Python interface to PROJ.4 library - Google Project Hosting:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\CFKHKMA4\\pyproj.html:text/html}
}

@inproceedings{harris_combined_1988,
	title = {A Combined Corner and Edge Detector},
	abstract = {Consistency of image edge filtering is of prime importance for 3D interpretation of image sequences using feature tracking algorithms. To cater for image regions containing texture and isolated features, a combined corner and edge detector based on the local auto-correlation function is utilised, and it is shown to perform with good consistency on natural imagery.},
	booktitle = {Proceedings of the Fourth Alvey Vision Conference},
	author = {Harris, Chris and Stephens, Mike},
	year = {1988},
	pages = {147--151},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\ZQ9DCKMF\\Harris and Stephens - 1988 - A combined corner and edge detector.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\TJ9FSUDK\\summary.html:text/html}
}

@misc{_python_????,
	title = {Python},
	url = {http://www.python.org/},
	urldate = {2013-06-02}
}

@article{aulinas_local_2010,
	title = {Local Map Update for Large Scale {SLAM}},
	volume = {46},
	issn = {0013-5194},
	doi = {10.1049/el.2010.2271},
	abstract = {A technique for simultaneous localisation and mapping ({SLAM}) for large scale scenarios is presented. This solution is based on the use of independent submaps of a limited size to map large areas. In addition, a global stochastic map, containing the links between adjacent submaps, is built. The information in both levels is corrected every time a loop is closed: local maps are updated with the information from overlapping maps, and the global stochastic map is optimised by means of constrained minimisation.},
	number = {8},
	journal = {Electronics Letters},
	author = {Aulinas, J. and Salvi, J. and Llado, X. and Petillot, Y.},
	year = {2010},
	keywords = {constrained minimisation, global stochastic map, graph theory, Kalman filters, large scale {SLAM}, local map update, minimisation, simultaneous localisation and mapping, {SLAM} (robots)},
	pages = {564--566},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\WWEWV9E6\\login.html:text/html}
}

@misc{_athena_????,
	title = {Athena 111m Integrated Flight Control System},
	url = {http://www.rockwellcollins.com},
	urldate = {2013-06-02}
}

@article{plumet_toward_2014,
	title = {Toward an Autonomous Sailing Boat},
	volume = {{PP}},
	issn = {0364-9059},
	doi = {10.1109/JOE.2014.2321714},
	abstract = {Among autonomous surface vehicles, sailing robotics could be a promising technology for long-term missions and semipersistent presence in the oceans. Autonomy of such vehicles in terms of energy will be achieved by renewable solar and wind power sources. Autonomy in terms of sailing decision will be achieved by innovative perception and navigation modules. The main contribution of this paper is to propose a complete hardware and software architecture for an autonomous sailing robot. The hardware architecture includes a comprehensive set of sensors and actuators as well as a solar panel and a wind turbine. For obstacle detection, a segmentation is performed on data coming from an omnidirectional camera coupled with an inertial measurement unit and a sonar. For navigation and control of the vehicle, a potential-based reactive path-planning approach is proposed. The specific sailboat kinematic constraints are turned into virtual obstacles to compute a feasible and optimal heading in terms of cost of gybe and tack maneuver as well as safety relative to obstacle danger. Finally, field test experiments are presented to validate the various components of the system.},
	number = {99},
	journal = {{IEEE} Journal of Oceanic Engineering},
	author = {Plumet, F. and Petres, C. and Romero-Ramirez, M.-A. and Gas, B. and Ieng, S.-H.},
	year = {2014},
	keywords = {Autonomous sailing robot, marine robotics, obstacle avoidance, omnidirectional vision, reactive path planning},
	pages = {1--11},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\6CAPHJG6\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\8VAMERMH\\Plumet et al. - 2014 - Toward an Autonomous Sailing Boat.pdf:application/pdf}
}

@inproceedings{kubota_global_2007,
	title = {A Global Optimization Algorithm for Real-Time On-Board Stereo Obstacle Detection Systems},
	doi = {10.1109/IVS.2007.4290083},
	abstract = {A fast and robust stereo algorithm for on-board obstacle detection systems is proposed. The proposed method finds the optimum road-obstacle boundary which provides the most consistent interpretation of the input stereo image pair. Global optimization combined with a robust matching measure enables stable detection of obstacles under various circumstances, such as heavy rain and severe lighting conditions. The processing time for {VGA} size image pair is about 15 msec on a 3.6 {GHz} pentium {IV} processor, which is fast enough for realtime applications.},
	booktitle = {Proceedings of the {IEEE} Intelligent Vehicles Symposium},
	author = {Kubota, S. and Nakano, T. and Okamoto, Y.},
	year = {2007},
	keywords = {Apertures, Cameras, Computational efficiency, global optimization algorithm, object detection, optimisation, optimum road-obstacle boundary, Rain, Real time systems, real-time on-board stereo obstacle detection systems, road safety, road traffic, Roads, Robustness, Search methods, stereo image, stereo image processing, stereo vision, traffic engineering computing, Vehicle detection},
	pages = {7--12},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\V4J275UG\\articleDetails.html:text/html}
}

@article{schleicher_real-time_2009,
	title = {Real-Time Hierarchical Outdoor {SLAM} Based on Stereovision and {GPS} Fusion},
	volume = {10},
	issn = {1524-9050},
	doi = {10.1109/TITS.2009.2026317},
	abstract = {This paper presents a new real-time hierarchical (topological/metric) simultaneous localization and mapping ({SLAM}) system. It can be applied to the robust localization of a vehicle in large-scale outdoor urban environments, improving the current vehicle navigation systems, most of which are only based on Global Positioning System ({GPS}). Then, it can be used on autonomous vehicle guidance with recurrent trajectories (bus journeys, theme park internal journeys, etc.). It is exclusively based on the information provided by both a low-cost, wide-angle stereo camera and a low-cost {GPS}. Our approach divides the whole map into local submaps identified by the so-called fingerprints (vehicle poses). In this submap level (low-level {SLAM}), a metric approach is carried out. There, a 3-D sequential mapping of visual natural landmarks and the vehicle location/orientation are obtained using a top-down Bayesian method to model the dynamic behavior. {GPS} measurements are integrated within this low-level improving vehicle positioning. A higher topological level (high-level {SLAM}) based on fingerprints and the multilevel relaxation ({MLR}) algorithm has been added to reduce the global error within the map, keeping real-time constraints. This level provides nearly consistent estimation, keeping a small degradation with {GPS} unavailability. Some experimental results for large-scale outdoor urban environments are presented, showing an almost constant processing time.},
	number = {3},
	journal = {{IEEE} Transactions on Intelligent Transportation Systems},
	author = {Schleicher, D. and Bergasa, L.M. and Ocana, M. and Barea, R. and Lopez, M.E.},
	year = {2009},
	keywords = {3-D sequential mapping, automated highways, autonomous vehicle guidance, Bayes methods, fingerprint, Global Positioning System, Global Positioning System ({GPS}), {GPS}, multilevel relaxation algorithm, outdoor simultaneous localization and mapping ({SLAM}), outdoor urban environment, real-time hierarchical outdoor {SLAM}, recurrent trajectories, relaxation, road vehicles, robust vehicle localization, simultaneous localization and mapping system, stereo camera, stereo image processing, stereovision, top-down Bayesian method, vehicle navigation system, vehicle positioning},
	pages = {440--452},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\AZ6EJ42P\\login.html:text/html}
}

@inproceedings{csorba_new_1996,
	title = {New Approach to Simultaneous Localization and Dynamic Map Building},
	volume = {2738},
	doi = {10.1117/12.241084},
	abstract = {A new method for simultaneous vehicle localization and dynamic map building is described. The method models the noise sources as bounded distributions and can therefore produce bounded estimates for the vehicle and all the target positions. Correlations that arise between vehicle and target estimates when using other techniques, such as the Kalman filter, do not arise, and hence a significant saving in memory and computation is achieved.},
	urldate = {2013-08-24},
	booktitle = {Proceeding of the {SPIE} 2738, Navigation and Control Technologies for Unmanned Systems},
	author = {Csorba, Michael and Uhlmann, Jeffrey K. and Durrant-Whyte, Hugh F.},
	year = {1996},
	pages = {26--36}
}

@book{maybeck_stochastic_1979,
	address = {New York},
	title = {Stochastic Models, Estimation and Control},
	isbn = {0124807011},
	number = {v.141},
	publisher = {Academic Press},
	author = {Maybeck, Peter S.},
	year = {1979},
	keywords = {Control theory, Estimation theory, System analysis}
}

@misc{subharsanan_low_2013,
	title = {Low Cost  Scanning {LiDAR} Imager},
	url = {http://www.lidarnews.com/PDF/LiDARMagazine_SudharsananMoss-LowCostLiDARImager_Vol3No2.pdf},
	publisher = {{LiDAR} News},
	author = {Subharsanan, Rengarajan and Moss, Robert},
	month = mar,
	year = {2013}
}

@article{yu_robust_2008,
	title = {Robust 3-{D} Motion Tracking From Stereo Images: A Model-Less Method},
	volume = {57},
	issn = {0018-9456},
	shorttitle = {Robust 3-D Motion Tracking From Stereo Images},
	doi = {10.1109/TIM.2007.911641},
	abstract = {Traditional vision-based 3-D motion-estimation algorithms require given or calculated 3-D models while the motion is being tracked. We propose a high-speed extended-Kalman-filter-based approach that recovers camera position and orientation from stereo image sequences without prior knowledge, as well as the procedure for the reconstruction of 3-D structures. Empowered by the use of a trifocal tensor, the computation step of 3-D models can be eliminated. The algorithm is thus flexible and can be applied to a wide range of domains. The twist motion model is also adopted to parameterize the 3-D motion. It is minimal since it only has six parameters as opposed to seven parameters in quaternion and 12 parameters in matrix representation. The motion representation is robust because it does not suffer from singularities as Euler angles. Due to the fact that the number of parameters to be estimated is reduced, our algorithm is more efficient, stable, and accurate than traditional approaches. The proposed method has been applied to recover the motion from stereo image sequences taken by a robot and a handheld stereo rig. The results are accurate compared to the ground truths. It is shown in the experiment that our algorithm is not susceptible to outlying point features with the application of a validation gate.},
	number = {3},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Yu, Ying-Kin and Wong, Kin Hong and Or, Siu Hang and Chang, M.M.-Y.},
	year = {2008},
	keywords = {computer vision, Euler angles, extended-Kalman-fllter-based approach, filtering theory, image sequences, Kalman filtering, Kalman filters, matrix algebra, matrix representation, motion estimation, pose tracking, robot vision, robust 3D motion tracking, stereo image processing, stereo image sequences, stereo images, stereo vision, structure and motion, trifocal tensor, twist, validation gate, vision-based 3D motion-estimation algorithms, visual servoing},
	pages = {622--630},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\Q8JBTE7M\\login.html:text/html}
}

@inproceedings{eade_scalable_2006,
	title = {Scalable Monocular {SLAM}},
	volume = {1},
	doi = {10.1109/CVPR.2006.263},
	abstract = {Localization and mapping in unknown environments becomes more difficult as the complexity of the environment increases. With conventional techniques, the cost of maintaining estimates rises rapidly with the number of landmarks mapped. We present a monocular {SLAM} system that employs a particle filter and top-down search to allow realtime performance while mapping large numbers of landmarks. To our knowledge, we are the first to apply this {FastSLAM}-type particle filter to single-camera {SLAM}. We also introduce a novel partial initialization procedure that efficiently determines the depth of new landmarks. Moreover, we use information available in observations of new landmarks to improve camera pose estimates. Results show the system operating in real-time on a standard workstation while mapping hundreds of landmarks.},
	booktitle = {Proceedings of the {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Eade, E. and Drummond, Tom},
	year = {2006},
	keywords = {Bayesian methods, Cameras, computer vision, Costs, Filtering, Navigation, Particle filters, Recursive estimation, Robots, Simultaneous localization and mapping},
	pages = {469--476},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\G8QIJSI6\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\W45A9MST\\Eade and Drummond - 2006 - Scalable Monocular SLAM.pdf:application/pdf}
}

@inproceedings{zhang_real-time_2012,
	title = {Real-time Obstacle Detection Based on Stereo Vision for Automotive Applications},
	doi = {10.1109/EDERC.2012.6532272},
	abstract = {This paper presents a novel algorithm for on-road obstacle detection based on stereo cameras. The proposed algorithm significantly reduces the complexity disparity calculations involved when using a stereo vision technique. Many recent stereo-vision based obstacle detection systems require a dense disparity map and, then, locate the obstacles according to the depth information. However, calculating the correspondence for each pixel is very time consuming. In automotive applications object detection must be performed in real-time. The proposed algorithm uses given parameters of stereo cameras to determine the disparity search range of the pixels assuming all the pixels are on the road surface. According to the predefined search range for the road surface, the true disparities of obstacles are not included. Therefore, large errors will be introduced during block matching which indicate obstacle positions. This new system only consumes less than 10\% of the traditional block-based disparity calculations. The core part of the proposed algorithm was implemented on the {TI} {DM}648 platform and achieved real-time performance.},
	booktitle = {Proceedings of the 5th European {DSP} Education and Research Conference},
	author = {Zhang, Zhen and Wang, Yifei and Brand, J. and Dahnoun, N.},
	year = {2012},
	keywords = {automotive applications, Automotive engineering, block matching, block-based disparity calculations, Cameras, complexity disparity calculations, dense disparity map, depth information, image matching, object detection, obstacle positions, on-road obstacle detection, real-time obstacle detection, road surface, stereo cameras, stereo image processing, stereo vision technique, stereo-vision based obstacle detection systems, {TI} {DM}648 platform},
	pages = {281--285},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\593QXZRF\\articleDetails.html:text/html}
}

@phdthesis{williams_efficient_2001,
	title = {Efficient Solutions to Autonomous Mapping and Navigation Problems},
	abstract = {This thesis deals with the Simultaneous Localisation and Mapping algorithm as it pertains to the deployment of mobile systems in unknown environments. Simultaneous Localisation and Mapping ({SLAM}) as defined in this thesis is the process of concurrently building up a map of the environment and using this map to obtain improved estimates of the location of the vehicle. In essence, the vehicle relies on its ability to extract useful navigation information from the data returned by its sensors. The vehicle typically starts at an unknown location with no a priori knowledge of landmark locations. From relative observations of landmarks, it simultaneously computes an estimate of vehicle location and an estimate of landmark locations. While continuing in motion, the vehicle builds a complete map of landmarks and uses these to provide continuous estimates of the vehicle location. The potential for this type of navigation system for autonomous systems operating in unknown environments is enormous. One significant obstacle on the road to the implementation and deployment of large scale {SLAM} algorithms is the computational effort required to maintain the correlation information between features in the map and between the features and the vehicle. Performing the update of the covariance matrix is of O(n3) for a straightforward implementation of the Kalman Filter. In the case of the {SLAM} algorithm, this complexity can be reduced to O(n2) given the sparse nature of typical observations. Even so, this implies that the computational effort will grow with the square of the number of features maintained in the map. For maps containing more than a few tens of features, this computational burden will quickly make the update intractable - especially if the observation rates are high. An effective map-management technique is therefore required in order to help manage this complexity. The major contributions of this thesis arise from the formulation of a new approach to the mapping of terrain features that provides improved computational efficiency in the {SLAM} algorithm. Rather than incorporating every observation directly into the global map of the environment, the Constrained Local Submap Filter ({CLSF}) relies on creating an independent, local submap of the features in the immediate vicinity of the vehicle. This local submap is then periodically fused into the global map of the environment. This representation is shown to reduce the computational complexity of maintaining the global map estimates as well as improving the data association process by allowing the association decisions to be deferred until an improved local picture of the environment is available. This approach also lends itself well to three natural extensions to the representation that are also outlined in the thesis. These include the prospect of deploying multi-vehicle {SLAM}, the Constrained Relative Submap Filter and a novel feature initialisation technique. Results of this work are presented both in simulation and using real data collected during deployment of a submersible vehicle equipped with scanning sonar.},
	school = {University of Sydney},
	author = {Williams, Stefan Bernard},
	year = {2001},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\SSDC6TVK\\Williams - 2001 - Efficient Solutions to Autonomous Mapping and Navi.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GV3C2SI9\\summary.html:text/html}
}

@inproceedings{leonard_simultaneous_1991,
	title = {Simultaneous Map Building and Localization for an Autonomous Mobile Robot},
	doi = {10.1109/IROS.1991.174711},
	abstract = {Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of `which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Workshop on Intelligent Robots and Systems},
	author = {Leonard, J.J. and Durrant-Whyte, H.F.},
	year = {1991},
	keywords = {autonomous mobile robot, computerised navigation, Humans, localization, long-term globally referenced position estimation, map building, mobile robots, multiple servo-mounted sonar sensors, National electric code, path planning, planning (artificial intelligence), precise positioning, Robot sensing systems, Sensor phenomena and characterization, Sonar navigation, Stochastic resonance, Target tracking, Testing, ultrasonic sensing, Vehicles},
	pages = {1442--1447 vol.3},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\SMZM2QUT\\login.html:text/html}
}

@article{durrant-whyte_simultaneous_2006,
	title = {Simultaneous Localization and Mapping: Part {I}},
	volume = {13},
	issn = {1070-9932},
	shorttitle = {Simultaneous localization and mapping},
	doi = {10.1109/MRA.2006.1638022},
	abstract = {This paper describes the simultaneous localization and mapping ({SLAM}) problem and the essential methods for solving the {SLAM} problem and summarizes key implementations and demonstrations of the method. While there are still many practical issues to overcome, especially in more complex outdoor environments, the general {SLAM} method is now a well understood and established part of robotics. Another part of the tutorial summarized more recent works in addressing some of the remaining issues in {SLAM}, including computation, feature representation, and data association},
	number = {2},
	journal = {{IEEE} Robotics Automation Magazine},
	author = {Durrant-Whyte, H. and Bailey, Tim},
	year = {2006},
	keywords = {Artificial intelligence, Bayesian methods, Buildings, History, mobile robots, Navigation, Particle filters, path planning, Robotics and automation, Simultaneous localization and mapping, simultaneous localization and mapping problem, {SLAM} problem, Vehicles},
	pages = {99--110},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\B6EXJIJM\\login.html:text/html}
}

@inproceedings{broggi_stereo_2011,
	title = {Stereo Obstacle Detection in Challenging Environments: The {VIAC} Experience},
	shorttitle = {Stereo obstacle detection in challenging environments},
	doi = {10.1109/IROS.2011.6094535},
	abstract = {Obstacle detection by means of stereo-vision is a fundamental task in computer vision, which has spurred a lot of research over the years, especially in the field of vehicular robotics. The information provided by this class of algorithms is used both in driving assistance systems and in autonomous vehicles, so the quality of the results and the processing times become critical, as detection failures or delays can have serious consequences. The obstacle detection system presented in this paper has been extensively tested during {VIAC}, the {VisLab} Intercontinental Autonomous Challenge [1], [2], which has offered a unique chance to face a number of different scenarios along the roads of two continents, in a variety of conditions; data collected during the expedition has also become a reference benchmark for further algorithm improvements.},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Broggi, A. and Buzzoni, M. and Felisa, M. and Zani, P.},
	year = {2011},
	keywords = {autonomous vehicle, Cameras, collision avoidance, computer vision, delay systems, delays, detection failures, driving assistance system, Hardware, image reconstruction, Image resolution, Measurement, mobile robots, road vehicles, Roads, robot vision, stereo image processing, stereo obstacle detection, stereo-vision, Vehicles, vehicular robotics, {VIAC}, {VisLab} Intercontinental Autonomous Challenge},
	pages = {1599--1604},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\UQ36CH7U\\articleDetails.html:text/html}
}

@inproceedings{civera_1-point_2009,
	title = {1-point {RANSAC} for {EKF}-based structure from motion},
	isbn = {978-1-4244-3803-7},
	abstract = {Recently, classical pairwise Structure From Motion ({SfM}) techniques have been combined with non-linear global optimization (Bundle Adjustment, {BA}) over a sliding window to recursively provide camera pose and feature location estimation from long image sequences. Normally called Visual Odometry, these algorithms are nowadays able to estimate with impressive accuracy trajectories of hundreds of meters; either from an image sequence (usually stereo) as the only input, or combining visual and propioceptive information from inertial sensors or wheel odometry. This paper has a double objective. First, we aim to illustrate for the first time how similar accuracy and trajectory length can be achieved by filtering-based visual {SLAM} methods. Specifically, a camera-centered Extended Kalman Filter is used here to process a monocular sequence as the only input, with 6DOF motion estimated. Features are kept live in the filter while visible as the camera explores forward, and are deleted from the state once they go out of view. This permits an increase in the number of tracked features per frame from tens to around a hundred. While improving the accuracy of the estimation, it makes computationally infeasible the exhaustive Branch and Bound search performed by standard {JCBB} for match outlier rejection. As a second contribution that overcomes this problem, we present here a {RANSAC}-like algorithm that exploits the probabilistic prediction of the filter. This use of prior information makes it possible to reduce the size of the minimal data subset to instantiate a hypothesis to the minimum possible of 1 point, greatly increasing the efficiency of the outlier rejection stage. Experimental results from real image sequences covering trajectories of hundreds of meters are presented and compared against {RTK} {GPS} ground truth. Estimation errors are about 1\% of the trajectory for trajectories up to 650 metres.},
	urldate = {2013-09-11},
	booktitle = {Proceedings of the {IEEE}/{RSJ} international conference on Intelligent robots and systems},
	author = {Civera, Javier and Grasa, Oscar G. and Davison, Andrew J. and Montiel, J. M. M.},
	year = {2009},
	pages = {3498--3504}
}

@article{jirawimut_visual_2003,
	title = {Visual Odometer for Pedestrian Navigation},
	volume = {52},
	issn = {0018-9456},
	doi = {10.1109/TIM.2003.815996},
	abstract = {This paper presents a visual odometer system using stereo cameras for pedestrian navigation. A novel method for pedestrian navigation based on the knowledge of gait analysis and robust ego-motion estimation is proposed. Two major problems of implementing the system on a pedestrian are stated. Firstly, the features collected from cameras attached on a walking pedestrian normally have winding trajectory resulting in inaccurate tracking. Secondly, the observed object moving independently leads to incorrect ego-motion estimation. Using gait analysis, capturing images at the same stage of the walking cycle produces a less winding trajectory that allows tracking without stabilizing the images. Robust ego motion is also introduced to eliminate outliers that are independently moving features, mismatched features in the stereo matching step and incorrectly assigned features in the tracking step. Data processing techniques including corner detection, stereo matching, triangulation, tracking, and ego-motion estimation are employed. The outcome is the estimated incremental ego motion of the stereo cameras. The approach not only enables the system to operate on walking users but also improves the accuracy of ego-motion estimation.},
	number = {4},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Jirawimut, R. and Prakoonwit, S. and Cecelja, F. and Balachandran, W.},
	year = {2003},
	keywords = {blind person, Cameras, corner detection, data processing, distance measurement, feature detection, gait analysis, Global Positioning System, handicapped aids, image capture, Layout, Legged locomotion, motion estimation, Navigation, pedestrian navigation, Robot vision systems, robust ego-motion estimation, Robustness, stereo camera, stereo image processing, stereo matching, Systems engineering and theory, Tracking, Trajectory, triangulation, visual odometer, visually impaired person, walking cycle, winding trajectory},
	pages = {1166--1173},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\T33EPG34\\login.html:text/html}
}

@article{kalman_new_1960,
	title = {A New Approach to Linear Filtering and Prediction Problems},
	volume = {82},
	issn = {0098-2202},
	doi = {10.1115/1.3662552},
	abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
	number = {1},
	urldate = {2013-08-14},
	journal = {Journal of Basic Engineering},
	author = {Kalman, R. E.},
	month = mar,
	year = {1960},
	pages = {35--45}
}

@article{williams_automatic_2011,
	title = {Automatic Relocalization and Loop Closing for Real-Time Monocular {SLAM}},
	volume = {33},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2011.41},
	abstract = {Monocular {SLAM} has the potential to turn inexpensive cameras into powerful pose sensors for applications such as robotics and augmented reality. We present a relocalization module for such systems which solves some of the problems encountered by previous monocular {SLAM} systems-tracking failure, map merging, and loop closure detection. This module extends recent advances in keypoint recognition to determine the camera pose relative to the landmarks within a single frame time of 33 ms. We first show how this module can be used to improve the robustness of these systems. Blur, sudden motion, and occlusion can all cause tracking to fail, leading to a corrupted map. Using the relocalization module, the system can automatically detect and recover from tracking failure while preserving map integrity. Extensive tests show that the system can then reliably generate maps for long sequences even in the presence of frequent tracking failure. We then show that the relocalization module can be used to recognize overlap in maps, i.e., when the camera has returned to a previously mapped area. Having established an overlap, we determine the relative pose of the maps using trajectory alignment so that independent maps can be merged and loop closure events can be recognized. The system combining all of these abilities is able to map larger environments and for significantly longer periods than previous systems.},
	number = {9},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Williams, B. and Klein, G. and Reid, I.},
	year = {2011},
	keywords = {3D/stereo scene analysis, augmented reality, automatic relocalization module, autonomous vehicles., Cameras, keypoint recognition, loop closure detection, mobile robots, object tracking, powerful pose sensors, Real time systems, real-time monocular {SLAM}, robotics, Simultaneous localization and mapping, {SLAM} (robots), Three dimensional displays, Tracking, tracking failure, trajectory alignment, visual servoing, visual tracking},
	pages = {1699--1712},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\E8QX76HP\\login.html:text/html}
}

@inproceedings{leonard_consistent_2003,
	title = {Consistent, Convergent, and Constant-time {SLAM}},
	abstract = {This paper presents a new efficient algorithm for simultaneous localization and mapping ({SLAM}), using multiple overlapping submaps, each built with respect to a local frame of reference defined by one of the features in the submap. The global position of each submap is estimated using information from other submaps in an efficient, provably consistent manner. For situations where the mobile robot is able to make repeated visits to all regions of the environment, the method achieves convergence to a near-optimal result with time complexity while maintaining consistent error bounds. Simulation results demonstrate the ability of the technique to converge to errors that are only slightly greater than the full solution, while maintaining consistency. 1},
	booktitle = {Proceedings of the 18th international joint conference on Artificial intelligence},
	author = {Leonard, J. and Newman, P.},
	year = {2003},
	pages = {1143--1150},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\HVNAF68I\\Leonard and Newman - 2003 - Consistent, convergent, and constant-time slam.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\FQJ6N758\\summary.html:text/html}
}

@inproceedings{nieuwenhuisen_obstacle_2014,
	title = {Obstacle detection and navigation planning for autonomous micro aerial vehicles},
	doi = {10.1109/ICUAS.2014.6842355},
	abstract = {Obstacle detection and real-time planning of collision-free trajectories are key for the fully autonomous operation of micro aerial vehicles in restricted environments. In this paper, we propose a complete system with a multimodal sensor setup for omnidirectional obstacle perception consisting of a 3D laser scanner, two stereo camera pairs, and ultrasonic distance sensors. Detected obstacles are aggregated in egocentric local multiresolution grid maps. We generate trajectories in a multi-layered approach: from mission planning to global and local trajectory planning, to reactive obstacle avoidance. We evaluate our approach in simulation and with the real autonomous micro aerial vehicle.},
	booktitle = {Proceedings of the 2014 International Conference on Unmanned Aircraft Systems},
	author = {Nieuwenhuisen, M. and Droeschel, D. and Beul, M. and Behnke, S.},
	month = may,
	year = {2014},
	keywords = {3D laser scanner, autonomous aerial vehicles, autonomous micro aerial vehicles, Cameras, collision avoidance, collision-free trajectories, egocentric local multiresolution grid maps, fully autonomous operation, global trajectory planning, local trajectory planning, Measurement by laser beam, mission planning, multimodal sensor setup, Navigation, navigation planning, obstacle detection, omnidirectional obstacle perception, optical scanners, Planning, planning (artificial intelligence), real autonomous micro aerial vehicle, real-time planning, Robot sensing systems, sensors, stereo camera pairs, stereo image processing, Three-dimensional displays, ultrasonic distance sensors},
	pages = {1040--1047},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\JIAAUQR2\\articleDetails.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\D4Q6UZIH\\Nieuwenhuisen et al. - 2014 - Obstacle detection and navigation planning for aut.pdf:application/pdf}
}

@book{brown_introduction_1993,
	address = {New York},
	edition = {2nd ed},
	title = {Introduction to Random Signals and Applied {K}alman Filtering},
	isbn = {0471525731},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Brown, Robert Grover},
	collaborator = {Hwang, Patrick Y. C.},
	year = {1993}
}

@techreport{james_geosurv_2008,
	title = {{GeoSurv} {II} {UAV} System Requirements Document},
	institution = {Carleton University},
	author = {James, Thomas},
	month = mar,
	year = {2008},
	file = {GeoSurvII System Requirements Document-SRD_E_31-Mar-08.pdf:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\8IQKHQ2W\\GeoSurvII System Requirements Document-SRD_E_31-Mar-08.pdf:application/pdf}
}

@misc{_opencv_????,
	title = {{OpenCV}},
	url = {http://opencv.org/}
}

@article{alonge_novel_2009,
	title = {A Novel Method of Distance Measurement Based on Pulse Position Modulation and Synchronization of Chaotic Signals Using Ultrasonic Radar Systems},
	volume = {58},
	issn = {0018-9456},
	doi = {10.1109/TIM.2008.2003309},
	abstract = {This paper deals with a novel method of transmission and receipt of a signal based on both the property of two chaotic systems generating the same chaotic signal when they are synchronized and the property of pulse position modulation ({PPM}) to be insensitive to the distortions of the transmission channel. The method is discussed in the context of ultrasonic radar systems, in which the transmitter and receiver, which consist of ultrasonic sensors, are near each other, and the received signal consists of the transmitted signal reflected by an obstacle. A reference sinusoidal signal is superimposed to a chaotic signal generated by a master chaotic system, and the whole signal is modulated according to the {PPM} method and transmitted by the sensor. The received signal is demodulated, and the demodulated signal forces a slave chaotic system to generate the chaotic signal embedded in it, which allows recovery of the sinusoidal signal by subtracting this chaotic signal from the demodulated echo. The difference of the phases of the reference sinusoidal signal and the recovered sinusoidal signal allows computation of the time of flight of the signal and, consequently, the distance of the radar system from the obstacle. The novel method is illustrated and tested by both simulation and experiments. The interference problem between the considered radar system and other radar systems ( crosstalk) is also addressed, and a solution is proposed to avoid it.},
	number = {2},
	journal = {{IEEE} Transactions on Instrumentation and Measurement},
	author = {Alonge, F. and Branciforte, M. and Motta, F.},
	year = {2009},
	keywords = {chaos, Chaotic pulse position modulation ({CPPM}), chaotic signal synchronization, chaotic system synchronization, chaotic systems, crosstalk, demodulation, distance measurement, multipath fading, {PPM}, pulse position modulation, radar applications, reference sinusoidal signal, time of flight, ultrasonic devices, ultrasonic radar systems, ultrasonic sensors},
	pages = {318--329},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\35MNKUTG\\login.html:text/html}
}

@article{zhang_flexible_2000,
	title = {A Flexible New Technique for Camera Calibration},
	volume = {22},
	issn = {0162-8828},
	doi = {10.1109/34.888718},
	abstract = {We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.},
	number = {11},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Zhengyou},
	year = {2000},
	keywords = {3D computer vision, Calibration, Camera calibration, Cameras, Closed-form solution, Computer simulation, computer vision, flexible technique, geometry, image sensors, Layout, Lenses, matrix algebra, maximum likelihood criterion, maximum likelihood estimation, Nonlinear distortion, optimisation, planar pattern, radial lens distortion, Testing},
	pages = {1330--1334},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\GJK5EM64\\login.html:text/html}
}

@inproceedings{julier_non-divergent_1997,
	title = {A Non-divergent Estimation Algorithm in the Presence of Unknown Correlations},
	volume = {4},
	doi = {10.1109/ACC.1997.609105},
	abstract = {This paper addresses the problem of estimation when the cross-correlation in the errors between different random variables are unknown. A new data fusion algorithm, the covariance intersection algorithm ({CI}), is presented. It is proved that this algorithm yields consistent estimates irrespective of the actual correlations. This property is illustrated in an application of decentralised estimation where it is impossible to consistently use a Kalman filter},
	booktitle = {Proceedings of the American Control Conference},
	author = {Julier, S.J. and Uhlmann, J.K.},
	year = {1997},
	keywords = {covariance intersection algorithm, covariance matrix, cross-correlation, data fusion algorithm, filtering theory, Information filtering, Information filters, nondivergent estimation algorithm, Predictive models, random variables, sensor fusion, Sensor systems, state estimation, unknown correlations, Vehicles, Yield estimation},
	pages = {2369--2373 vol.4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\I8FW65U2\\login.html:text/html}
}

@book{bradski_learning_2008,
	title = {Learning {OpenCV}: Computer Vision with the {OpenCV} Library},
	isbn = {9780596554040},
	shorttitle = {Learning {OpenCV}},
	abstract = {"This library is useful for practitioners, and is an excellent tool for those entering the field: it is a set of computer vision algorithms that work as advertised." -William T. Freeman, Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology Learning {OpenCV} puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source {OpenCV} library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on that data.  Computer vision is everywhere-in security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. It stitches Google maps and Google Earth together, checks the pixels on {LCD} screens, and makes sure the stitches in your shirt are sewn properly. {OpenCV} provides an easy-to-use computer vision framework and a comprehensive library with more than 500 functions that can run vision code in real time. Learning {OpenCV} will teach any developer or hobbyist to use the framework quickly with the help of hands-on exercises in each chapter. This book includes: A thorough introduction to {OpenCV} Getting input from cameras Transforming images Segmenting images and shape matching Pattern recognition, including face detection Tracking and motion in 2 and 3 dimensions 3D reconstruction from stereo vision Machine learning algorithms  Getting machines to see is a challenging but entertaining goal. Whether you want to build simple or sophisticated vision applications, Learning {OpenCV} is the book you need to get started.},
	language = {en},
	publisher = {O'Reilly Media, Inc.},
	author = {Bradski, Gary and Kaehler, Adrian},
	month = oct,
	year = {2008},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Programming Languages / C, Technology \& Engineering / Robotics}
}

@inproceedings{garcia_multi-sensory_2008,
	title = {Multi-sensory System for Obstacle Detection on Railways},
	doi = {10.1109/IMTC.2008.4547393},
	abstract = {In the current railway systems, it is becoming more necessary to have safety elements in order to avoid accidents. One of the causes that can provoke serious accidents is the existence of obstacles on the tracks. In this work, a multi-sensory barrier - consisting of infrared ({IR}) and ultrasonic ({US}) sensors- and a vision system, is proposed in order to inform the monitoring system of the existence of obstacles. Due to the fact that any sensor has detection problems which are strongly dependent on meteorological conditions, the use of different sensors for the same task is justified so that the drawback of one sensor is compensated for by the others. The high degree of reliability needed in these environments, where the safety is fundamental, recommends the use of a multi-sensory system. Principal components analysis is applied to the data obtain from the barrier and from the vision system. The use of this technique with the barrier permits concluding if there are obstacles on the tracks; and with the vision system information about moving objects is obtained.},
	booktitle = {Proceeding of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Garcia, J.J.D. and Urena, J.U. and Hernandez, A.A. and Mazo, M.Q. and Vazquez, J.F. and Diaz, M.-J.},
	year = {2008},
	keywords = {accident prevention, Accidents, collision avoidance, false alarms reduction, infrared detectors, infrared sensor, Laser radar, Machine vision, meteorological condition, multisensory system, Multi-sensory system, object detection, obstacle detection, obstacle monitoring system, principal component analysis, principal components analysis, Proposals, Rail transportation, railway accidents, railway engineering, railway safety, railway tracks, railways, safety elements, sensor emission codification, Sensor systems, ultrasonic devices, ultrasonic sensors, Vehicles, vision system information},
	pages = {2091--2096},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\KB5KU8Z4\\login.html:text/html}
}

@inproceedings{de_angelis_low-cost_2007,
	title = {A Low-Cost Ultra-Wideband Indoor Ranging Technique},
	doi = {10.1109/IMTC.2007.379419},
	abstract = {This paper presents the development of a low-cost indoor ranging technique based on time-of-arrival ({TOA}) estimation, using short-pulse ultra-wideband ({UWB}) signals. The realized system includes two identical {UWB} transceiver devices, in which the receiver section is based on a tunnel diode detector and the pulse generation is performed by a common bipolar transistor driven in avalanche mode. An indirect measurement of the distance between the devices is obtained by measuring the frequency of the generated pulse train. A theoretical model of the system is described and a statistical analysis is presented, including the evaluation of the Cramer-Rao lower bound ({CRLB}) on the distance estimation. Furthermore the principle of operation of the realized system prototypes is described, along with some implementation issues. Finally experimental results are shown and discussed.},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {De Angelis, A. and Dionigi, M. and Moschitta, A. and Carbone, P.},
	year = {2007},
	keywords = {avalanche diodes, avalanche mode, Bandwidth, common bipolar transistor, Cramer-Rao lower bound, Delay, distance measurement, {FCC}, Frequency measurement, geolocation, Ground penetrating radar, indoor ranging, Instrumentation and measurement, pulse generation, Pulse measurements, short-pulse ultra-wideband signals, statistical analysis, time-of-arrival estimation, time-of-flight, {TOA} estimation, transceivers, tunnel diode detector, tunnel diodes, ultra wideband communication, ultra wideband technology, ultra-wideband, ultra-wideband indoor ranging technique, {UWB} signals, {UWB} transceiver devices},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\BFTRFJ68\\login.html:text/html}
}

@inproceedings{curtis_integrated_2005,
	title = {An Integrated Robotic Multi-Modal Range Sensing System},
	volume = {3},
	doi = {10.1109/IMTC.2005.1604520},
	abstract = {Creating 3-D surface representation of large objects or wide working areas is a tedious and error-prone process using the currently available sensor technologies. The primary problem comes from the fact that laser range sensors allow to capture at most one line of points from a given position and orientation, and stereo vision systems accuracy is dependent upon the initial camera calibration, the extraction of features, and the matching of features. When the registration process is not properly controlled, registration errors tend to significantly degrade the accuracy of measurements, which is revealed to be critical in telerobotic operations where occupancy models are built directly from these range measurements. The reliability of range measurements within a singular range sensor technique can drastically distort the registration process, especially within environments unsuitable for the system. Instead of utilizing a single range sensor, we adopt the use of a multi-modal system allowing diverse modes of range sensing techniques to complement each other in the hope that one system's strength could be used to compensate for another system's weakness. Using a mixture of active and passive range sensing techniques, both giving dense and sparse datasets, this multi-modal range sensing system is integrated seamlessly with minimal processing overhead and optimal workspace},
	booktitle = {Proceedings of the {IEEE} International Instrumentation and Measurement Technology Conference},
	author = {Curtis, P. and Yang, C.S. and Payeur, P.},
	year = {2005},
	keywords = {active range sensing, Calibration, Cameras, data fusion, Degradation, distance measurement, Distortion measurement, diverse modes, Error correction, feature extraction, Feature extraction, integrated robotic multi modal range sensing, multi-modal data collection, passive range sensing, range measurements, Robot sensing systems, robotic sensing systems, Robots, sensor fusion, Sensor phenomena and characterization, Sensor systems, stereo vision},
	pages = {1991--1996},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\XWFJ7F6W\\login.html:text/html}
}

@article{smith_representation_1986,
	title = {On the Representation and Estimation of Spatial Uncertainty},
	volume = {5},
	issn = {0278-3649, 1741-3176},
	doi = {10.1177/027836498600500404},
	abstract = {This paper describes a general method for estimating the nominal relationship and expected error (covariance) between coordinate frames representing the relative locations of ob jects. The frames may be known only indirectly through a series of spatial relationships, each with its associated error, arising from diverse causes, including positioning errors, measurement errors, or tolerances in part dimensions. This estimation method can be used to answer such questions as whether a camera attached to a robot is likely to have a particular reference object in its field of view. The calculated estimates agree well with those from an independent Monte Carlo simulation. The method makes it possible to decide in advance whether an uncertain relationship is known accu rately enough for some task and, if not, how much of an improvement in locational knowledge a proposed sensor will provide. The method presented can be generalized to six degrees offreedom and provides a practical means of esti mating the relationships ( position and orientation) among objects, as well as estimating the uncertainty associated with the relationships.},
	language = {en},
	number = {4},
	urldate = {2013-08-24},
	journal = {The International Journal of Robotics Research},
	author = {Smith, Randall C. and Cheeseman, Peter},
	month = dec,
	year = {1986},
	pages = {56--68},
	file = {Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\7NAAF6FC\\56.html:text/html}
}

@misc{_google_????,
	title = {Google {Earth}},
	url = {http://www.google.com/earth/},
	urldate = {2013-06-12},
	file = {Athena 111m Integrated Flight Control System:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\K666RZVI\\Athena_111m_Integrated_Flight_Control_System.html:text/html}
}

@inproceedings{castellanos_limits_2004,
	title = {Limits to the Consistency of {EKF}-Based {SLAM}},
	abstract = {Abstract: This paper analyzes the consistency of the classical extended Kalman filter ({EKF}) solution to the simultaneous localization and map building ({SLAM}) problem. Our results show that in large environments the map quickly becomes inconsistent due to linearization errors. We propose a new {EKF}-based {SLAM} algorithm, robocentric mapping, that greatly reduces linearization errors, improving map consistency. We also present results showing that large-scale mapping methods based on building local maps with a local uncertainty representation (Tardós et al., 2002) have better consistency than methods that work with global uncertainties.},
	booktitle = {Proceedings of the 5th {IFAC} Symposium Intelligent Autonomous Vehicles},
	author = {Castellanos, José A. and Neira, José and Tardós, Juan D.},
	year = {2004},
	file = {Citeseer - Full Text PDF:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\D4546G2M\\Castellanos et al. - Limits to the Consistency of Ekf-Based Slam 1.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\HA7KZK3R\\summary.html:text/html}
}

@inproceedings{sunderhauf_using_2007,
	title = {Using the Unscented {K}alman Filter in Mono-{SLAM} with Inverse Depth Parametrization for Autonomous Airship Control},
	doi = {10.1109/SSRR.2007.4381265},
	abstract = {In this paper, we present an approach for aiding control of an autonomous airship by the means of {SLAM}. We show how the Unscented Kalman Filter can be applied in a {SLAM} context with monocular vision. The recently published Inverse Depth Parametrization is used for undelayed single-hypothesis landmark initialization and modelling. The novelty of the presented approach lies in the combination of {UKF}, Inverse Depth Parametrization and bearing-only {SLAM} and its application for autonomous airship control and {UAV} control in general.},
	booktitle = {Proceedings of the {IEEE} International Workshop on Safety, Security and Rescue Robotics},
	author = {Sunderhauf, N. and Lange, S. and Protzel, P.},
	year = {2007},
	keywords = {Acceleration, aerospace robotics, aircraft control, airship, autonomous airship control, bearing-only {SLAM}, Cameras, Fires, Global Positioning System, inverse depth parametrization, Kalman filters, mobile robots, monocular {SLAM}, monocular vision, mono-{SLAM}, Optical receivers, Optical sensors, Remotely operated vehicles, robot vision, Robots, Simultaneous localization and mapping, {SLAM} (robots), {UAV} control, undelayed single-hypothesis landmark initialization, Unmanned aerial vehicles, unscented Kalman filter},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\BKV2UZF5\\login.html:text/html}
}

@inproceedings{einhorn_cant_2010,
	title = {Can't Take My Eye Off You: Attention-driven Monocular Obstacle Detection and {3D} Mapping},
	shorttitle = {Can't take my eye off you},
	doi = {10.1109/IROS.2010.5651741},
	abstract = {Robust and reliable obstacle detection is an important capability for mobile robots. In our previous works we have presented an approach for visual obstacle detection based on feature based monocular scene-reconstruction. Most existing feature-based approaches for visual {SLAM} and scene reconstruction select their features uniformly over the whole image based on visual saliency only. In this paper we present a novel attention-driven approach that guides the feature selection to image areas that provide the most information for mapping and obstacle detection. Therefore, we present an information theoretic derivation of the expected information gain that results from the selection of new image features. Additionally, we present a method for building a volumetric representation of the robots environment in terms of an occupancy voxel map. The voxel map provides top-down information that is needed for computing the expected information gain. We show that our approach for guided feature selection improves the quality of the created voxel maps and improves the obstacle detection by reducing the risk of missing obstacles.},
	booktitle = {Proceedings of the {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	author = {Einhorn, E. and Schröter, C. and Gross, H. M},
	year = {2010},
	keywords = {3D mapping, attention driven approach, attention driven monocular obstacle detection, collision avoidance, {EKF}, feature selection, image feature, information gain, mobile robots, monocular scene reconstruction, shape-from-motion, {SLAM} (robots), visual attention, visual obstacle detection, visual saliency, Visual {SLAM}, volumetric representation, voxel map, voxel mapping},
	pages = {816--821},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\fan\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\ovsi675t.default\\zotero\\storage\\QTVFTQ6G\\articleDetails.html:text/html}
}

@inproceedings{Byrne_stereo_2006,
	title = {Stereo based obstacle detection for an unmanned air vehicle},
	doi = {10.1109/ROBOT.2006.1642130},
	booktitle = {Proceedings of IEEE International Conference on Robotics and Automation},
	author = {Byrne, J. and Cosgrove, M. and Mehra, R.},
	year = {2006},
	pages = {2830--2835},
}

@inproceedings{pinies_inertial_2007,
	title = {Inertial Aiding of Inverse Depth {SLAM} using a Monocular Camera},
	doi = {10.1109/ROBOT.2007.363895},
	booktitle = {Proceedings of IEEE International Conference on Robotics and Automation},
	author = {Pinies, P. and Lupton, T. and Sukkarieh, S. and Tardos, J.D.},
	year = {2007},
	pages = {2797--2802},
}

@inproceedings{li_scene_2012,
	title = {Scene matching based {EKF-SLAM} visual navigation},
	booktitle = {Proceedings of the 2012 31st Chinese Control Conference},
	author = {Li, Y. and Pan, Q. and Zhao, C. and Yang, F.},
	year = {2012},
	pages = {5094--5099},

}
