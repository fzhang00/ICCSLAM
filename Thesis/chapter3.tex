\chapter{Algorithm Description}\label{ch:algorithm}

The algorithm described in this chapter and its preliminary test
result on real flight data was published in
\cite{zhang_obstacle_2012}. The program was implemented in Python
programming language\cite{_python_????}. An open source machine
vision library OpenCV\cite{_opencv_????} was utilized to perform feature extraction and
tracking. The Shi-Tomasi corner detector \cite{shi_good_1994} was used
to extract corner features from the image sequence. Feature tracking
was accomplished through the pyramid implementation of Lucas-Kanade
optical flow method \cite{bouguet_pyramidal_1999}.

\section{Camera Centric Inverse Depth Parameterization}
Figure \ref{fig:algo1} shows the feature parameters definition in inverse
depth parameterization.

\begin{figure}[h]
\centering
\includegraphics[width=10cm, keepaspectratio=true]{./Figures/idp.jpg}
\caption{Inverse Depth Parameterization}
\label{fig:algo1}
\end{figure}

\noindent A 3D scene point $p_{i}^{C}$ can be defined by 6 parameters
with $i$ representing the feature number, and the superscript $C$
indicating that the parameter is represented in camera reference frame.
\begin{equation}
\mathbf{p_{i}^{C}}=\begin{bmatrix}
x_{i}^{C} & y_{i}^{C} & z_{i}^{C} & \rho _{i} & \varphi _{i}^{C} & 
\theta _{i}^{C} 
\end{bmatrix}
\end{equation}
The first three parameters $[x_{i}^{C}, y_{i}^{C}, z_{i}^{C}]$
represent the initialization point where the feature is first observed.
$\rho_{i} = 1/d_i$ is the inverse distance from the initialization position
to the feature. The elevation-azimuth pair $[\varphi_{i}^{C},
\theta_{i}^{C}]$ encodes a unit vector pointing from the
initialization point to the feature. The vector is given by
\begin{equation}
\label{eq:m}
\vec{\mathbf{m}}(\varphi_{i}^{C}, \theta_{i}^{C})=\begin{bmatrix}
\cos\varphi_{i}^{C}\cos\theta _{i}^{C} \\
\cos\varphi_{i}^{C}\sin\theta _{i}^{C} \\
\sin\varphi_{i}^{C}
\end{bmatrix}
\end{equation}

\noindent Given the a vector $[h_x, h_y, h_z]$, one can also find the
elevation-azimuth angles $[\varphi, \theta]$ by

\begin{equation}
\label{eq:m_inv_varphi}
\varphi 
=arctan\left(\frac{h_{z}}{\sqrt{h_x^2+h_y^2}}\right)
\end{equation}

\begin{equation}
\label{eq:m_inv_theta}
\theta =arctan\left(\frac{h_{y}}{h_{x}}\right)
\end{equation}


\section{Modeling the System with Extended Kalman 
Filter}

\subsection{Full State Vector}

The EKF full state vector is defined as 

\begin{equation}
\mathbf{x}=\begin{bmatrix}
\mathbf{OX_{W}^{C}} & \mathbf{c^{C}} & \mathbf{r^{C}} & 
\mathbf{p_{1}^{C}} & \mathbf{p_{2}^{C}} & \ldots 
\end{bmatrix}^T
\end{equation}

\noindent where $\mathbf{OX_{W}^{C}}= \begin{bmatrix}O_{x}^{C} &
  O_{y}^{C} & O_{z}^{C} & W_{x}^{C} & W_{y}^{C} &
  W_{z}^{C} \end{bmatrix}^{T}$ contains translation parameters
$\mathbf{O_{x,y,z}^{C}}$ and rotation parameters
$\mathbf{W_{x,y,z}^{C}}$ that represent the world frame position and
orientation referenced to the camera frame.
$\left(\mathbf{c^{C}},\mathbf{r^{C}}\right)^{T}$ represent the camera
translation and rotation motion frame by frame. $\mathbf{p_{i}^{C}}$
contains the feature parameters described in the previous section.

\subsection{Prediction}

For a prediction step at time $k$, the world frame parameter
$\mathbf{OX_W^C}$ and features parameters $\mathbf{p_i^C}$ are kept
unchanged from time $k-1$. The camera parameters are updated using the
new inertial measurements: velocity $\mathbf{v^{C}}$, acceleration
$\mathbf{a^{C}}$, and rate of change $\mathbf{w^{C}}$ in roll, pitch, and
azimuth. The full state vector at time $k$ is
\begin{equation}
\mathbf{x_{predicted}}
=\begin{bmatrix}
\mathbf{OX_{W,k-1}^{C}} & 
\mathbf{c_{measured}^{C}} &
\mathbf{r_{measured}^{C}} & 
\mathbf{p_{1,k-1}^{C}} & 
\mathbf{p_{2,k-1}^{C}} & 
\ldots & 
\mathbf{p_{n,k-1}^C}
\end{bmatrix}^T
\end{equation}

\noindent where 

$$\mathbf{c_{measured}^{C}}=\mathbf{v_{measured}^{C}}\Delta t+ 
\frac{1}{2}\mathbf{a_{measured}^{C}}\Delta t^{2}$$
$$\mathbf{r_{measured}^{C}}=\mathbf{r_{k-1}^{C}}+ \mathbf{w_{measured}^{C}}$$

\noindent and $\Delta t$ is the time elapsed from frame to frame. 

\subsection{Measurement Model}

Each observed feature is related to the camera motion through the
measurement model (figure \ref{fig:measurement_model}). This
relationship enables a correction on the camera motion and features
parameters based on the features locations observed in the image.

\begin{figure}[h]
\centering
\includegraphics[width=9cm, keepaspectratio=true]{./Figures/measurement_model.jpg}
\caption{Measurement Model}
\label{fig:measurement_model}
\end{figure}
\FloatBarrier
For a feature $\mathbf{p_{i}^{C}}$, the vector $\mathbf{i^{C}}$
pointing from the predicted camera location to the feature
initialization position is

\begin{equation}
\mathbf{i_{k}^{C}}=\begin{bmatrix}
x_{i}^{C} \\
y_{i}^{C} \\
z_{i}^{C} \\
\end{bmatrix}_{k}-\begin{bmatrix}
c_{x}^{C} \\
c_{y}^{C} \\
c_{z}^{C} \\
\end{bmatrix}_{k}
\end{equation}

The normalized vector pointing from the predicted camera position to the 
feature at time k is then 
\begin{equation}
  \mathbf{h_{k}^{C}}=\mathbf{Q}^{-1}\left(\mathbf{r_{k}^{C}}\right)
  \left(\rho_{k}\mathbf{i_{k}^{C}}+
    \mathbf{m}\left(\varphi_k^{C},\theta _{k}^{C}\right)\right)
\end{equation}

\noindent where $\mathbf{Q}^{-1}(\mathbf{r_{k}^{C}})$ is the inverse
rotation matrix from the camera frame at time $k-1$ to camera frame at
time $k$. From vector $\mathbf{h_{k}^{C}}$, the feature location on
image plane can be found by

\begin{equation}
\mathbf{h_{k}^{U}}= \begin{bmatrix}
u_{k} \\
v_{k} \\
\end{bmatrix}=\begin{bmatrix}
\frac{f_{x}h_{y,k}^{C}}{h_{x,k}^{C}} \\
\frac{f_{y}h_{z,k}^{C}}{h_{x,k}^{C}} \\
\end{bmatrix}
\end{equation}

\noindent where $f_{x}$ and $f_{y}$ is the scaling factor of the projection 
obtained through camera calibration.

Since the measurement model is non-linear, the equation must be
linearized to calculate the Kalman gain $K$. Detail formulation for
linearization is given in appendix \ref{sec:jac_measurement}.

\subsection{Composition Step}

The corrected state vector has all its parameters defined in camera
frame at time $k-1$. To keep reference frame up-to-date, a coordinate
transformation is needed to transform all parameters, and error matrix
into camera frame at step k so that the next cycle of tracking can be
continued. This step is referred to as the composition. To
differentiate the camera frame, a subscript $k$ and $k-1$ are added to
the reference frame indicator $C$.

World reference frame parameters is transformed using the equation

\begin{equation}
\begin{bmatrix}
O_{x}^{C_{k}} \\
O_{y}^{C_k} \\
O_{z}^{C_k} \\
\end{bmatrix}_{k}=\mathbf{Q}^{-1}(\mathbf{r_{k}^{C_{k-1}}})\left(
\begin{bmatrix}
O_{x}^{C_{k-1}} \\
O_{y}^{C_{k-1}} \\
O_{z}^{C_{k-1}} \\
\end{bmatrix}_{k}- \begin{bmatrix}
c_{x}^{C_{k-1}} \\
c_{y}^{C_{k-1}} \\
c_{z}^{C_{k-1}} \\
\end{bmatrix}_{k}\right)
\end{equation}

\noindent and
\begin{equation}
\begin{bmatrix}
W_{x}^{C_{k}} \\
W_{y}^{C_{k}} \\
W_{z}^{C_{k}} \\
\end{bmatrix}_{k}= \begin{bmatrix}
W_{x}^{C_{k-1}} \\
W_{y}^{C_{k-1}} \\
W_{z}^{C_{k-1}} \\
\end{bmatrix}_{k}-\mathbf{r_k^{C_{k-1}}}
\end{equation}
 
Landmarks parameters in the camera reference frame are related to the
previous reference frame 
by

\begin{equation}
\begin{bmatrix}
x_{i}^{C_{k}} \\
y_{i}^{C_{k}} \\
z_{i}^{C_{k}} \\
\end{bmatrix}_{k}=\mathbf{Q}^{-1}(\mathbf{r_k^{C_{k-1}}})\left(
\begin{bmatrix}
x_{i}^{C_{k-1}} \\
y_{i}^{C_{k-1}} \\
z_{i}^{C_{k-1}} \\
\end{bmatrix}_{k}- \begin{bmatrix}
c_{x}^{C_{k-1}} \\
c_{y}^{C_{k-1}} \\
c_{z}^{C_{k-1}} \\
\end{bmatrix}_{k}\right)
\end{equation}

\noindent and
\begin{equation}
\begin{bmatrix}
\rho_{i} \\
\varphi_{i}^{C_{k}} \\
\theta_{i}^{C_{k}} \\
\end{bmatrix}_{k}=
\begin{bmatrix}
\rho _{i} \\
\mathbf{m}^{-1}\left(\mathbf{Q}^{-1}(\mathbf{r_k^{C_{k-1}}})\mathbf{m}(\varphi _{i, k}^{C_{k-1}}, \theta _{i, k}^{C_{k-1}})\right) \\
\end{bmatrix}
\end{equation}

\noindent where $\rho_i$ is a scaler that doesn't require transformation.
$\mathbf{m}^{-1}$ represents the operator that convert
the unit vector back to $[\varphi, \theta]$ angles as defined in
equation (\ref{eq:m_inv_varphi}) (\ref{eq:m_inv_theta}).

The covariance matrix is also affected by this transformation. The new
covariance matrix is related to the old one by

\begin{equation}
\mathbf{P_{k}^{C_{k}}}=\mathbf{J_{C_{k-1}\to C_{k}}}\mathbf{P_{k}^{C_{k-1}}}\mathbf{J_{C_{k-1}\to C_{k}}^{T}}
\end{equation}

\noindent where $\mathbf{J_{C_{k-1} \to C_k}}$ is the Jacobian matrix of the
composition equations. Detail derivation of the Jacobian matrix is
given in appendix \ref{sec:jac_composition}  

\subsection{Filter Initialization} \label{sec:filter_initialization}
\subsubsection{Initialize the State Vector}

State vector is initialized at the first frame. The world frame
position and orientation, camera motions, and the feature
initialization points are all initialized to zeros, with variance
equals to the smallest machine number.

\begin{equation}
\label{eq:OX_init}
\mathbf{OX_{W}^{C}}=\begin{bmatrix}0&0&0&0&0&0\end{bmatrix}^T 
\end{equation}

\begin{equation}
\mathbf{c^{C}}=\begin{bmatrix}0&0&0\end{bmatrix}^T
\end{equation}

\begin{equation}
\mathbf{r^{C}}=\begin{bmatrix}0&0&0\end{bmatrix}^T
\end{equation}

\begin{equation}
\label{eq:pi_init}
\mathbf{p_{i}^{C}}=\begin{bmatrix}0&0&0&\rho _{i}&\varphi_{i}^C&\theta_{i}^C\end{bmatrix}^T
\end{equation}

The inverse distance $\rho$ of all features are initialized to 0.1
($d=100 meters$). The features elevation-azimuth pair $[\varphi _{i}^{C},
\theta _{i}^{C}]$ is extracted from features coordinates in image
plane. First, a vector pointing from camera optical center to feature
can be defined by
\begin{equation}
\label{eq:init_feature_unit_vec}
\mathbf{h^{C}}=\begin{bmatrix}
h_{x}^{C}\\
h_{y}^{C}\\
h_{z}^{C}\\
\end{bmatrix}
 = \begin{bmatrix}
1 \\
(u-c_x)/f_{x} \\
(v-c_y)/f_{y} \\
\end{bmatrix}
\end{equation}

\noindent where $[u, v]$ is the feature coordinate in the image, $
[f_{x}, f_{y}]$ is the scaling factor of the projection from the scene
to image plane, $[c_x, c_y]$ is the coordinate at which the optical axis
intersects the image plane. The elevation-azimuth pair $[\varphi
_{i}^{C}, \theta _{i}^{C}]$ can be directly calculated from
$\mathbf{h^{C}}$ using equation (\ref{eq:m_inv_varphi}) and (\ref{eq:m_inv_theta})

\subsubsection{Initialized the State Covariance Matrix}

As the world reference frame is defined by the camera reference frame
at time 0, it allowed the filter to be initialized with minimum
variance, which helps to reduce the lower bound of the filter error
according to the EKF SLAM properties. The covariance matrix for the
world reference frame position and orientation, and the camera motion is

\begin{equation}
\label{eq:Pinit}
\mathbf{P}=\mathbf{I_{12\times 12}}\cdot \epsilon 
\end{equation}

\noindent where $\epsilon $ is the lowest significant bit (LSB) of a
computer.

The covariance of landmark is added one by one as there is 
correlation between them. For every new landmark added, the new 
covariance matrix becomes

\begin{equation}
\label{eq:Pnew}
\mathbf{P_{new}}=\mathbf{J}\begin{bmatrix}
\mathbf{P_{old}} & \mathbf{0} \\
\mathbf{0} & \mathbf{R} \\
\end{bmatrix}
\mathbf{J}^{T}
\end{equation}

\noindent where $\mathbf{P_{old}}$ is the covariance matrix of the existing
state vector. The initial $\mathbf{P_{old}}$ before the first landmark is
added is equation (\ref{eq:Pinit}). Matrix $\mathbf{R}$ is given by.

\begin{equation}
\label{eq:R}
\mathbf{R}=\begin{bmatrix}
\sigma _{x_{i}^{C}} & & & & & & \\
 & \sigma _{y_{i}^{C}} & & & 0 & & \\
 & & \sigma _{z_{i}^{C}} & & & & \\
 & & & \sigma _{\rho } & & & \\
 & 0 & & & \sigma _{image} & & \\
 & & & & & \sigma _{image} & \\
\end{bmatrix}
 = \begin{bmatrix}
\epsilon & & & & & & \\
 & \epsilon & & & 0 & & \\
 & & \epsilon & & & & \\
 & & & 0.1 & & & \\
 & 0 & & & 1 & & \\
 & & & & & 1 & \\
\end{bmatrix} 
\end{equation}

\noindent where $[\sigma_{x_{i}}^{C}, \sigma_{y_{i}}^{C}, \sigma
_{z_{i}}^{C}]$ is the uncertainty of the camera optical center
position, initialized to $\epsilon$. $\sigma_{image}$ is the
variance of landmark coordinate on image plane, set to 1 pixel. $\sigma
_{\rho }$ is the uncertainty of the inverse distance. Because the
filter mainly deals with distanced landmark, $ \sigma _{\rho }$ is
initialized to 0.1 to cover distance from 50 meters to infinity.

$\mathbf{J}$ in equation (\ref{eq:Pnew}) is the Jacobian matrix for
the landmark initialization equations given in equations
(\ref{eq:OX_init})-(\ref{eq:pi_init}),
(\ref{eq:m_inv_varphi}), and (\ref{eq:m_inv_theta}). Detail
formulation of the Jacobian matrix is given in appendix
\ref{ch:appendix2}.



\subsection{Adding and Deleting Landmarks}
To shorten processing time for each iteration, landmarks that moved
out of the camera's field of view (FOV) are removed from the filter
state vector and covariance matrix. The removal is done by deleting
the parameters from the state vector, and the related rows and columns
from the state covariance matrix. All tracked landmarks were recorded
into a database. The deleted landmarks had their parameters updated
based on the camera motion, but no Kalman correction were done.

While some landmarks were deleted, new landmarks were added to the
filter to maintain sufficient amount of landmarks for mapping. The
landmarks addition occurred after the composition step of each
iteration, and followed the same procedure as the filter
initialization described in section \ref{sec:filter_initialization}.
Flow chart of the entire algorithm is shown in figure
\ref{fig:flowchart}.

\begin{figure}[h]
\centering
\includegraphics[width=14cm, keepaspectratio=true]{./Figures/flow_chart.jpg}
\caption{Algorithm Flow Chart}
\label{fig:flowchart}
\end{figure}

% \subsubsection{Bundle Correction with GPS (not yet implemented)}
% Apply overall correction on the map at a sparser time interval using the 
% GPS positions. 


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
